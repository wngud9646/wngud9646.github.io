---
title:  "데이터베이스"
excerpt: "DevOps 부트캠프 Section 1 "

categories:
  - Blog
tags:
  - [Blog, DevOps]

toc: true
toc_sticky: true
 
date: 2023-03-29
last_modified_at: 2023-03-29
---
# 데이터베이스
## 데이터와 정보의 차이점

데이터: 데이터란 현실 세계에서 단순한 관찰이나 측정을 통해서 수집된 사실 또는 값이 어떤 기준에 의해 정리되어 있는 것

정보: 어떠한 상황에서 적절한 의사 결정을 할 수 있도록 지원하는 지식

컴퓨터 시스템과 같은 처리기를 통한 데이터의 유효한 해석이나 데이터 상호간의 관계

### *“정보는 데이터가 어떤 목적에 의해 해석되거나 가공된 형태임”*

<br><br>

## 데이터베이스의 정의
### Database란?
어느 한 조직의 다양한 응용 프로그램들이 공동으로 사용하는 데이터들을 통합하여 저장한 운영 데이터의 집합 <br>
사람들이 필요로 하는 데이터를 모아둔 것<br>
(*1963.06 미국 SDC사에서(제 1차 심포지엄) 데이터 베이스란 용어가 공식적으로 처음 사용<br>
1965.06 미국 SDC사에서(제 2차 심포지엄) 데이터베이스 시스템이란 용어가 공식적으로 처음 사용)<br>
옛: 저장장치에 저장된 파일 -> 현재: 운영 데이터의 집합


### 데이터 베이스의 정의에 함축된 개념
- 공용데이터: 한 조직의 여러 응용 프로그램들이 공동으로 사용하는 것 <br>
즉, 여러 사용자가 서로 다른 목적으로 공유함
- 통합된 데이터: 여러 부서에서 사용하는 데이터를 한 곳에 모아서 공동 관리하는 것 (기억장소 절약) <br>
원칙적으로 동일한 데이터의 중복을 허용하지 않지만, 검색의 효율성을 위해서 최소한의 중복(=통제된 중복)을 허용하여 통합함. <br>
(8최소한의 중복 => 부득이한 중복)
- 저장된 데이터:컴퓨터가 접근할 수 있는 디스크와 같은 저장 매체에 저장된 것
- 운영 데이터:조직의 운영에 기본적으로 반드시 필요한 데이터를 저장하는 것 <br>
조직의 고유한 기능을 수행하는데 필수적인 데이터를 저장하는 것 <br>
일시적으로 필요한 임시데이터나 단순한 입출력 데이터는 운영 데이터에 해당되지 않음


### 데이터베이스의 특징
- 동시 공용: 여러 응용 프로그램이나 사용자들이 서로 다른 목적으로 데이터를 동시에 사용할 수 있음
- 지속적인 변화: DB에 저장된 데이터는 고정된 것이 아니며, 삽입, 삭제, 갱신 등을 통해서 지속적으로 변화함으로써 현재의 정확한 데이터를 유지해야 함.
- 실시간 접근성: 컴퓨터가 접근할 수 있는 기록 매체에 저장되어 관리되므로, 언제든지 필요한 시점에 바로 접근 가능해야 함
즉, 어떤 질의에 대해 실시간에 바로 응답해야 함.
- 내용에 의한 참조: 데이터가 저장된 주소나 위치가 아닌, 데이터의 내용 즉, 값에 의해서 참조됨
즉, 사용자가 원하는 데이터의 조건을 명시하면, 조건을 만족하는 레코드가 어디에 위치하든 접근 가능함.
- 데이터베이스 관리 시스템에 의한 관리: DB의 구축 및 관리를 위해서 전용 소프트웨어인 DBMS가 필요함


### 데이터베이스 출현 배경
파일처리 시스템:각각의 응용 프로그램이 자신의 데이터를 파일 형태로 별도로 관리하는, 파일 중심의 데이터 관리 시스템

특징
- 데이터 종속성 (Data Dependency)
: 응용 프로그램과 데이터 간의 밀접한 연관성으로 인해, 데이터를 저장한 파일 구조가 변경되면 응용 프로그램도 변경해야 함.

- 데이터 중복성 (Data Redundancy)
: 응용 프로그램의 독립적인 파일 관리로 인해, 응용 프로그램 별로 독립된 파일을 가지므로 데이터의 중복 저장이 불가피하여 데이터 값의 불일치가 발생할 가능성이 매우 높음.

파일 처리 시스템의 문제점
- 데이터의 중복저장으로 인한 비효율성: 여러 파일에 동일한 데이터가 중복될 가능성이 높으므로, 저장 공간의 낭비, 유지 및 보수의 어려움, 데이터 보안의 어려움 등이 유발됨 <br>
(ex 회원 정보 관리와 등급 관리 같은 경우 중복된 내용이 있어 회원이 많을수록 기억공간의 낭비가 심화)

- 데이터 일관성 (Consistency) 유지의 어려움
: 동일한 데이터가 여러 파일에 흩어져 있으므로, 시간이 지남에 따라 동일한 데이터가 서로 다른 값을 가질 가능성이 커짐 <br>
(ex 동일한 파일이 두 개의 데이터 파일에 저장되어있을 경우 한쪽의 경우에서만 내용을 변경한 경우 양쪽 파일의 데이터 값이 서로 다르므로 데이터의 일관성이 유지되지 않음,) <br>
※ 데이터 일관성 = 중복된 데이터의 일치성에 관한 문제

- 데이터 무결성(Integrity) 유지의 어려움: 어떤 데이터가 반드시 만족해야 하는 무결성 제약조건을 일일이 프로그램에서 처리해야 하므로, 프로그램에서 빠뜨린 경우 무결성을 유지하기 어려움 <br>
(ex 데이터 입력시 기준치를 잘못 입력할 경우 프로그램에서 제약조건을 위반하게 됨, 원래 데이터 파일에 저장될 수 없는 데이터가 저장됨)<br>
※ 데이터 무결성 = 데이터 값이 미리 정의된 제약조건을 만족하는지를 의미하는 정확성에 관한 문제

무결성 유지 방법 <br>
파일 시스템에서 무결성 유지: 각각의 무결성 제약조건을 일일이 응용 프로그램에서 처리해야 함

데이터베이스에서의 무결성 유지: DB가 갱신될 때 마다 DBMS가 자동으로 제약조건의 만족 여부를 검사하므로 응용 프로그램에서 별도로 처리할 필요가 없음

- 데이터 공유의 어려움: 데이터의 구조가 응용 프로그램마다 다르므로 데이터 파일이 동일한 데이터를 포함하고 있어도 데이터 공유가 어려움<br>
(ex 동일한 데이터 프로그램을 사용하더라도 각각의 필드 크기를 다르게 정의했기에 대이터 공유가 어려움. ※ 필드 = 하나 이상의 필드가 모여서 하나의 레코드가 됨, 레코드= 하나 이상의 필드로 구성 된 정보의 최소 단위로서 파일은 하나 이상의 레코드로 구성되어 있음)

### DB 출현 배경과 파일 처리 시스템의 연관성
파일처리 시스템의 여러 문제점 때문에 DB가 출현되어 데이터 종속성, 중복성을 해결하여 여러 가지 문제점이 해결되고 구조적인 한계점을 극복하게 되었다.

※ 주의 - DB를 구축하는 것이 모든 환경에서 적합한 것은 아니므로 DBMS와 파일 처리 시스켐의 장단점을 잘 분석해서 선택해야 함

[출처](https://anndora628911.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%9D%98-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90) : 
https://anndora628911.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%9D%98-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90


### DB 구축의 필요성
![alt text](/images/db.png)


### DB의 장단점
![alt text](/images/dbs.png)

### DB의 개념적 구성요소
![alt text](/images/dbschema.png)

개념적 - 개체
개체 <br>
정의: DB가 저장하는 유형, 무형의 정보 대상으로, 존재하면서 서로 구별될 수 있는 요소 <br>
특징: 파일 시스템에서 ‘레코드’에 대응함 <br>
단독으로 존재 가능하고, 정보로서의 역할이 가능함<br>
하나 이상의 속성으로 구성됨<br>
종류: 유형의 개체: 사람, 집 등 물리적으로 존재하는 개체<br>
무형의 개체: 인사, 급여, 교과목 등 개념적으로 존재하는 개체

속성 <br>
정의: 개체의 특성을 나타내는 요소로, 이름을 가진 정보의 가장 작은 논리적인 단위<br>
특징: 파일 시스템에서 ‘데이터 항목’ 혹은 ‘필드’에 대응함<br>
단독으로 존재할 때는 대개 무의미함

개념적 - 관계
관계<br>
정의: 일반적으로 개체들 간의 의미 있는 연결 또는 연관성을 의미하는 요소<br>
특징: 관계도 하나의 개체로 간주될 수 있음<br>
속성 관계와 개체 관계로 세분할 수 있으며, 그냥 ‘관계’라고 하면 ‘개체 관계’를 의미함

유형: 일 대 일 (1:1) - 한 개 개체가 한 개 개체와 연관되어 있는 유형

일 대 다 (1:n) - 한 개 개체가 여러 개체와 연관성이 있는 유형

다 대 다 (n:m) - 여러 개체가 여러 개체와 연관성이 있는 유형


### DB의 저장 구조 구분
![alt text](/images/dbstorage.png)

논리적 구조: 물리적 저장 장치 위에 저장된 DB의 저장 구조를 사용자 관점에서 본 것으로, 사용자가 생각하는 데이터의 구조를 표현한 것

물리적 구조: 물리적 저장 장치 위에 저장된 DB의 저장구조를 시스템(저장 장치) 관점에서 본 것으로, 디스크와 같은 저장 장치에 저장되는 데이터의 실제 구조를 표현한 것

[출처](https://anndora628911.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1): https://anndora628911.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1

### SQL (관계형 DB)
SQL을 사용하면 RDBMS에서 데이터를 저장, 수정, 삭제 및 검색 할 수 있다.

관계형 데이터베이스에는 핵심적인 두 가지 특징이 있다.

데이터는 정해진 데이터 스키마에 따라 테이블에 저장된다.
데이터는 관계를 통해 여러 테이블에 분산된다.

데이터는 테이블에 레코드로 저장되는데, 각 테이블마다 명확하게 정의된 구조가 있다. 해당 구조는 필드의 이름과 데이터 유형으로 정의된다.

따라서 스키마를 준수하지 않은 레코드는 테이블에 추가할 수 없다. 즉, 스키마를 수정하지 않는 이상은 정해진 구조에 맞는 레코드만 추가가 가능한 것이 관계형 데이터베이스의 특징 중 하나다.

또한, 데이터의 중복을 피하기 위해 '관계'를 이용한다.

하나의 테이블에서 중복 없이 하나의 데이터만을 관리하기 때문에 다른 테이블에서 부정확한 데이터를 다룰 위험이 없어지는 장점이 있다.


### NoSQL (비관계형 DB)
말그대로 관계형 DB의 반대다.

스키마도 없고, 관계도 없다.

NoSQL에서는 레코드를 문서(documents)라고 부른다.

여기서 SQL과 핵심적인 차이가 있는데, SQL은 정해진 스키마를 따르지 않으면 데이터 추가가 불가능했다. 하지만 NoSQL에서는 다른 구조의 데이터를 같은 컬렉션에 추가가 가능하다.

문서(documents)는 Json과 비슷한 형태로 가지고 있다. 관계형 데이터베이스처럼 여러 테이블에 나누어담지 않고, 관련 데이터를 동일한 '컬렉션'에 넣는다.

따라서 위 사진에 SQL에서 진행한 Orders, Users, Products 테이블로 나눈 것을 NoSQL에서는 Orders에 한꺼번에 포함해서 저장하게 된다.

따라서 여러 테이블에 조인할 필요없이 이미 필요한 모든 것을 갖춘 문서를 작성하는 것이 NoSQL이다. (NoSQL에는 조인이라는 개념이 존재하지 않음)

그러면 조인하고 싶을 때 NoSQL은 어떻게 할까?

컬렉션을 통해 데이터를 복제하여 각 컬렉션 일부분에 속하는 데이터를 정확하게 산출하도록 한다.

하지만 이러면 데이터가 중복되어 서로 영향을 줄 위험이 있다. 따라서 조인을 잘 사용하지 않고 자주 변경되지 않는 데이터일 때 NoSQL을 쓰면 상당히 효율적이다.

#확장 개념
두 데이터베이스를 비교할 때 중요한 Scaling 개념도 존재한다.

데이터베이스 서버의 확장성은 '수직적' 확장과 '수평적' 확장으로 나누어진다.

수직적 확장 : 단순히 데이터베이스 서버의 성능을 향상시키는 것 (ex. CPU 업그레이드)
수평적 확장 : 더 많은 서버가 추가되고 데이터베이스가 전체적으로 분산됨을 의미 (하나의 데이터베이스에서 작동하지만 여러 호스트에서 작동)

데이터 저장 방식으로 인해 SQL 데이터베이스는 일반적으로 수직적 확장만 지원함

수평적 확장은 NoSQL 데이터베이스에서만 가능


### 장단점
SQL 장점 <br>
명확하게 정의된 스키마, 데이터 무결성 보장 <br>
관계는 각 데이터를 중복없이 한번만 저장

SQL 단점 <br>
덜 유연함. 데이터 스키마를 사전에 계획하고 알려야 함. (나중에 수정하기 힘듬) <br>
관계를 맺고 있어서 조인문이 많은 복잡한 쿼리가 만들어질 수 있음 <br>
대체로 수직적 확장만 가능함

NoSQL 장점 <br>
스키마가 없어서 유연함. 언제든지 저장된 데이터를 조정하고 새로운 필드 추가 가능 <br>
데이터는 애플리케이션이 필요로 하는 형식으로 저장됨. 데이터 읽어오는 속도 빨라짐 <br>
수직 및 수평 확장이 가능해서 애플리케이션이 발생시키는 모든 읽기/쓰기 요청 처리 가능

NoSQL 단점 <br>
유연성으로 인해 데이터 구조 결정을 미루게 될 수 있음 <br>
데이터 중복을 계속 업데이트 해야 함 <br>
데이터가 여러 컬렉션에 중복되어 있기 때문에 수정 시 모든 컬렉션에서 수행해야 함 (SQL에서는 중복 데이터가 없으므로 한번만 수행이 가능)


SQL 데이터베이스 사용이 더 좋을 때 <br>
관계를 맺고 있는 데이터가 자주 변경되는 애플리케이션의 경우 <br>
NoSQL에서는 여러 컬렉션을 모두 수정해야 하기 때문에 비효율적 <br>
변경될 여지가 없고, 명확한 스키마가 사용자와 데이터에게 중요한 경우


NoSQL 데이터베이스 사용이 더 좋을 때 <br>
정확한 데이터 구조를 알 수 없거나 변경/확장 될 수 있는 경우 <br>
읽기를 자주 하지만, 데이터 변경은 자주 없는 경우 <br>
데이터베이스를 수평으로 확장해야 하는 경우 (막대한 양의 데이터를 다뤄야 하는 경우)

<br><br>

## SQL
SQL(Structured Query Language, 구조적 질의 언어)은 관계형 데이터베이스 시스템(RDBMS)을 제어하는 컴퓨터 언어이다.

일반적인 프로그래밍 언어(범용 언어)와 달리 대화식 언어이기 때문에, 명령문이 짧고 간결하다. 

SQL 자체는 범용 언어에 비해 한계가 있기 때문에, 단독으로 사용하기 보단 C#, Java, Python, PHP와 같은 고수준 언어와 함께 쓰는 것이 일반적이다.

###  SQL 쿼리 문의 분류 
SQL 쿼리문은 역할에 따라 3가지로 분류되며 아래와 같다.

- DDL(Data Definition Language, 데이터 정의어) <br>
DB 오브젝트를 생성, 삭제, 변경하는 역할을 하며, DB 설계 단계에서 주로 사용된다. <br>(CREATE, DROP, ALTER...)
- DML(Data Manipulation Language, 데이터 조작어)<br>
DB를 조회, 삽입, 삭제, 변경하는 역할을 하며, 관리 목적의 쿼리문이다. <br>
(SELECT, INSERT, UPDATE...)
- DCL(Data Control Language, 데이터 제어어)<br>
사용자의 권한을 관리하는 역할을 한다. 
<br>(GRANT, DENY, REVOKE...)
 
이중 개발자가 일반적으로 DB를 사용할 때 사용하는 언어의 중요도는 DML > DDL > DCL 순이다.

DB를 조회하고, 관리하는 DML을 가장 많이 사용하며, DB의 테이블의 스키마(설계 수준)를 수정하는 DDL을 그다음으로 많이 쓴다.

DCL은 DBA(DataBase Administration, 데이터베이스 관리자)가 주로 사용하며 일반 개발자는 사용할 일이 드뭅니다.


###  SQL의 규칙
SQL은 DBMS에 따라 규칙이 약간은 달라질 수 있다. 하지만, 일반적인 규칙들은 아래와 같다. <br>
( tTable이라는 가상의 테이블이 있다고 가정하고 예시를 작성)

1.  SQL 명령은 세미콜론으로 마무리<br>
SQL은 명령이 끝나는 부분을 세미콜론(;)으로 구분한다. <br>
즉, 명령을 여러 줄에 걸쳐 작성하더라도 세미콜론을 마지막에 작성해주면 하나의 명령어로 인식한다.

```
-- 단일 라인 명령
SELECT * FROM tTable;
 
-- 멀티 라인 명령
SELECT * 
FROM tTable
WHERE city = 'Seoul';
```

2. 주석
  1) 단일 라인(Single Line) 주석: 맨 앞에 --를 붙여서 사용
```
-- Select Example (이 부분은 실행되지 않음)
SELECT * FROM tTable;
```
  2) 블록 주석(Multi Line): /* */로 감싸줍니다. 
```
/* 여러줄 주석 예시
Select All Records from tTable
Where city in Seoul (SQL의 조건문)
*/
SELECT * FROM tTable WHERE city = 'Seoul';
```

 

3. SQL은 보통 대소문자를 가리지 않는다.<br>
SQL 문법은 보통 문자열을 제외하곤 대소문자를 가리지 않지만, 대소문자 구분을 통해 가독성을 향상하는 것이 일반적이다.

예를 들어, 컬럼 이름은 소문자로 하고, DB이름은 첫 글자만 대문자로 하는 등 대소문자를 통해 컬럼과 DB를 구분할 수 있다. <br>
(DBMS에서 DB이름, 테이블이름, 컬럼이름 등에서 대소문자를 구분하도록 설정하는 경우도 있습니다.)

아래 예시는 명령어와 테이블 이름을 대소문자 구분없이 사용한 경우로, 똑같이 작동합니다.
```
-- 아래 두 명령어는 동치
SELECT * FROM tTable;
Select * from ttable;
```


## 인덱스(Index)
인덱스란 추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스 테이블의 검색 속도를 향상시키기 위한 자료구조이다.<br> 
만약 우리가 책에서 원하는 내용을 찾는다고 하면, 책의 모든 페이지를 찾아 보는것은 오랜 시간이 걸린다. <br>
그렇기 때문에 책의 저자들은 책의 맨 앞 또는 맨 뒤에 색인을 추가하는데, 데이터베이스의 index는 책의 색인과 같다.

데이터베이스에서도 테이블의 모든 데이터를 검색하면 시간이 오래 걸리기 때문에 데이터와 데이터의 위치를 포함한 자료구조를 생성하여 빠르게 조회할 수 있도록 돕고 있다.

인덱스를 활용하면, 데이터를 조회하는 SELECT 외에도 UPDATE나 DELETE의 성능이 함께 향상된다. 그러한 이유는 해당 연산을 수행하려면 해당 대상을 조회해야만 작업을 할 수 있기 때문이다.
```
// Mang이라는 이름을 업데이트 해주기 위해서는 Mang을 조회해야 한다.
UPDATE USER SET NAME = 'MangKyu' WHERE NAME = 'Mang';
```

만약 index를 사용하지 않은 컬럼을 조회해야 하는 상황이라면 전체를 탐색하는 Full Scan을 수행해야 한다. Full Scan은 전체를 비교하여 탐색하기 때문에 처리 속도가 떨어진다.

### 인덱스(index)의 관리
DBMS는 index를 항상 최신의 정렬된 상태로 유지해야 원하는 값을 빠르게 탐색할 수 있다. 그렇기 때문에 인덱스가 적용된 컬럼에 INSERT, UPDATE, DELETE가 수행된다면 각각 다음과 같은 연산을 추가적으로 해주어야 하며 그에 따른 오버헤드가 발생한다.

- INSERT: 새로운 데이터에 대한 인덱스를 추가함
- DELETE: 삭제하는 데이터의 인덱스를 사용하지 않는다는 작업을 진행함
- UPDATE: 기존의 인덱스를 사용하지 않음 처리하고, 갱신된 데이터에 대해 인덱스를 추가함


### 인덱스(index)의 장점과 단점
장점 <br>
테이블을 조회하는 속도와 그에 따른 성능을 향상시킬 수 있다.<br>
전반적인 시스템의 부하를 줄일 수 있다.
단점 <br>
인덱스를 관리하기 위해 DB의 약 10%에 해당하는 저장공간이 필요하다. <br>
인덱스를 관리하기 위해 추가 작업이 필요하다.<br>
인덱스를 잘못 사용할 경우 오히려 성능이 저하되는 역효과가 발생할 수 있다.

만약 CREATE, DELETE, UPDATE가 빈번한 속성에 인덱스를 걸게 되면 인덱스의 크기가 비대해져서 성능이 오히려 저하되는 역효과가 발생할 수 있다. <br>
그러한 이유 중 하나는 DELETE와 UPDATE 연산 때문이다. <br>
앞에서 설명한대로, UPDATE와 DELETE는 기존의 인덱스를 삭제하지 않고 '사용하지 않음' 처리를 해준다고 하였다.<br> 
만약 어떤 테이블에 UPDATE와 DELETE가 빈번하게 발생된다면 실제 데이터는 10만건이지만 인덱스는 100만 건이 넘어가게 되어, SQL문 처리 시 비대해진 인덱스에 의해 오히려 성능이 떨어지게 될 것이다. <br><br>

### 인덱스(index)를 사용하면 좋은 경우
- 규모가 작지 않은 테이블
- INSERT, UPDATE, DELETE가 자주 발생하지 않는 컬럼
- JOIN이나 WHERE 또는 ORDER BY에 자주 사용되는 컬럼
- 데이터의 중복도가 낮은 컬럼
- 기타 등등

인덱스를 사용하는 것 만큼이나 생성된 인덱스를 관리해주는 것도 중요하다. 그러므로 사용되지 않는 인덱스는 바로 제거를 해주어야 한다. 


## 인덱스(Index)의 자료구조
### 해시 테이블(Hash Table)
해시 테이블은 (Key, Value)로 데이터를 저장하는 자료구조 중 하나로 빠른 데이터 검색이 필요할 때 유용하다. <br>
해시 테이블은 Key값을 이용해 고유한 index를 생성하여 그 index에 저장된 값을 꺼내오는 구조이다

![alt text](/images/hashtable.png)

해시 테이블 기반의 DB 인덱스는 (데이터=컬럼의 값, 데이터의 위치)를 (Key, Value)로 사용하여 컬럼의 값으로 생성된 해시를 통해 인덱스를 구현하였다. <br>
해시 테이블의 시간복잡도는 O(1)이며 매우 빠른 검색을 지원한다.

하지만 DB 인덱스에서 해시 테이블이 사용되는 경우는 제한적인데, 그러한 이유는 해시가 등호(=) 연산에만 특화되었기 때문이다.<br> 
해시 함수는 값이 1이라도 달라지면 완전히 다른 해시 값을 생성하는데, 이러한 특성에 의해 부등호 연산(>, <)이 자주 사용되는 데이터베이스 검색을 위해서는 해시 테이블이 적합하지 않다.

즉, 예를 들면 "나는"으로 시작하는 모든 데이터를 검색하기 위한 쿼리문은 인덱스의 혜택을 전혀 받지 못하게 된다.<br> 
이러한 이유로 데이터베이스의 인덱스에서는 B+Tree가 일반적으로 사용된다.


### B+Tree 
B+Tree는 DB의 인덱스를 위해 자식 노드가 2개 이상인 B-Tree를 개선시킨 자료구조이다.<br>
B+Tree는 모든 노드에 데이터(Value)를 저장했던 BTree와 다른 특성을 가지고 있다.

- 리프노드(데이터노드)만 인덱스와 함께 데이터(Value)를 가지고 있고, 나머지 노드(인덱스노드)들은 데이터를 위한 인덱스(Key)만을 갖는다.
- 리프노드들은 LinkedList로 연결되어 있다.
- 데이터 노드 크기는 인덱스 노드의 크기와 같지 않아도 된다

데이터베이스의 인덱스 컬럼은 부등호를 이용한 순차 검색 연산이 자주 발생될 수 있다.<br> 
이러한 이유로 BTree의 리프노드들을 LinkedList로 연결하여 순차검색을 용이하게 하는 등 BTree를 인덱스에 맞게 최적화하였다.<br> 
(물론 Best Case에 대해 리프노드까지 가지 않아도 탐색할 수 있는 BTree에 비해 무조건 리프노드까지 가야한다는 단점도 있다.)

이러한 이유로 비록 B+Tree는 O(log2n
) 의 시간복잡도를 갖지만 해시테이블보다 인덱싱에 더욱 적합한 자료구조가 되었다.



## 복제(replication)
- 한 서버에서 다른 서버로 데이터를 동기화하는 것 
- 원본 데이터를 가지는 서버를 Source 서버 
- 복제된 데이터를 가지는 서버를 Replica 서버


### 쓰는 이유?
부하를 줄이기 위해서 (Scale-out)
- 갑자기 늘어나는 트래픽을 대응하는데 유연한 구조

데이터 백업
- 레플리카를 안하더라도 백업을 해야함
- 백업 과정은 실제 실행중인 쿼리들에 영향을 줄 수 있음
- 레플리카 서버에서 데이터 백업을 실행하여 소스 서버에서 백업 시 발생하는 문제 해결

데이터 분석
- 분석용 쿼리는 대량의 데이터를 조회하고, 쿼리 자체가 무거운 경우가 많음
- 소스 서버에서 하게 되면 문제가 될 수 있으니, 레플리카 서버에서 분석용 쿼리만 전용으로 하는 것이 좋음

데이터의 지리적 분산 
- 데이터베이스와 애플리케이션 서버가 멀리 떨어져있다면 응답을 늦게 받게됨
- 빠른 응답을 위해 애플리케이션 서버에 가깝게 서버를 구성하는 것이 좋음


### 복제를 하는 방법
바이너리 로그 (binlog)<br>
SQL 서버에서 발생하는 모든 변경사항을 별도의 로그 파일에 순서대로 저장
- 데이터의 변경내역
- 데이터베이스나 테이블의 구조 변경
- 계정이나 권한의 변경 정보

소스 서버에서 생성된 binlog가 레플리카 서버로 전송되고, 레플리카 서버에서는 해당 내용을 로컬 디스크에 저장한 뒤 자신이 가진 데이터에 반영하므로써 동기화가 이루어진다.

![alt text](/images/replica.png)

Binary Log Dump Thread
- 소스 서버에 존재
- binlog를 레플리카 서버로 전송하는 역할
- 레플리카 서버가 소스 서버에 연결되면 소스 서버에서 내부적으로 Binary Log Dump Thread를 생성

Replication I/O Thread
- 레플리카 서버에 존재
- Binary Log Event를 가져와 로컬 서버의 파일(Relay Log)로 저장하는 역할
- 복제가 시작될 때 스레드가 생성되고 복제가 끝나면 스레드 종료
- Connection Metadata
  - 소스 서버에 연결할 때 사용하는 정보를 가짐
  - mysql.slave_master_info 테이블에 저장 
- Replay Log
  - 가져온 바이너리 로그 이벤트를 레플리카 서버에 파일로 저장한 것 

Replication SQL Thread
- 레플리카 서버에 존재
- 릴레이 로그 파일의 이벤트들을 읽고 실행
- Applier Metadata
  - 릴레이 로그에 저장된 소스 서버의 이벤트들을 서버에 저장하는 컴포넌트
  - 소스서버에 연결할 때 사용하는 정보를 가짐
  - mysql.slave_relay_log_info 테이블에 저장


### 변경내용 식별
레플리케이션을 사용하려면 소스 서버에 반드시 binlog가 활성화되어 있어야한다. 

바이너리 로그 파일 위치 기반<br>
레플리카 서버에서 소스 서버의 binlog 파일명과 파일 내에서 위치로 binlog 이벤트를 식별해서 복제한다.<br>
이벤트가 최초로 발생한 MySQL 서버를 식별하기 위해 server_id를 사용한다.<br>
기본값은 1인데 레플리케이션을 하게 된다면 레플리카 서버에 반드시 server_id를 각각 다르게 지정해주어야 한다. 

글로벌 트랜잭션 ID 기반 (GTID)<br>
GTID<br>
복제에 참여한 서버들에서 고유하도록 각 이벤트에 부여된 식별 값을 의미한다. <br>
MySQL 5.5 버전까지는 바이너리 로그 파일 위치 기반 방식으로만 레플리케이션이 가능했다. <br>
하지만 이 방식은 식별 과정이 소스 서버에서만 유효하다. <br>
동일한 이벤트가 레플리카 서버에서 동일한 위치와 동일한 파일명으로 저장된다는 보장이 없다. <br>
어떤 경우에는 동일한 이벤트인데, 서로 다른 식별 값을 가지는 경우가 있을 것이다. <br>
이 문제를 해결하기 위해 각 이벤트들이 복제에 참여한 모든 MySQL 서버들에서 동일한 고유 식별 값을 가지게 하는 방법이다. 


### 바이너리 로그의 저장 방식
Statement 방식 <br>
SQL 문을 바이너리 로그에 그대로 기록<br>
MySQL에 binlog가 처음 도입되었을 때부터 있던 방식<br>
트랜잭션의 격리 수준이 반드시 REPEATABLE-READ 이상이어야 한다.
- 그 이하에서는 하나의 트랜잭션에서도 각 쿼리가 실행되는 시점마다 스냅샷이 달라질 수 있어 이로 인해 복제 시 서버와 레플리카 서버의 데이터가 일치하지 않을 수 있기 때문

장점
- 손쉽게 SQL문들을 확인할 수 있다.<br>

단점
- 비확정적(delete/update에 order by 없이 limit 사용 등 결과가 매번 달라질 수 있는 상황)으로 처리될 수 있는 쿼리가 실행된 경우 Statement 포맷에서는 복제 시 소스 서버와 레플리카 서버 간 데이터가 달라질 수 있다.

Row 방식<br>
변경된 데이터 자체를 기록<br>
MySQL 5.7.7 버전 이후부터 바이너리 로그 기본 포맷 

장점
- 어떤 형태의 쿼리든지 복제 시 소스 서버와 레플리카 서버의 데이터를 일관되게 한다. 

단점
- 많은 데이터를 변경하면 모든 데이터가 전부 기록되어 바이너리 로그 파일이 단 시간에 매우 커진다.
- 어떤 쿼리가 실행되었는지는 확인하기 어렵다.

Mixed 방식
- 위 두 방식을 혼합
- 쿼리의 대부분은 Statement 방식으로 기록될 확률이 높은데, 실행된 쿼리가 Statement 포맷으로 기록되어 복제됐을 때 문제가 될 가능성 있는 안전하지 못한 쿼리라면 Row 방식으로 기록


### 복제 동기화 방식
소스 서버가 레플리카 서버에 이벤트들이 잘 보내졌는지 안보내졌는지 확인하냐 안하냐에 따라 복제 동기화 방식을 설정할 수 있다.


비동기 복제
- 소스 서버가 레플리카 서버에서 변경 이벤트가 정상적으로 전달 되었는지 확인하지 않는다. 
- 소스 서버에 장애가 일어나면 소스 서버에서 최근까지 적용된 트랜잭션이 레플리카 서버로 전송되지 않을 수 있다.


반동기 복제
- 소스 서버는 레플리카 서버가 소스 서버로부터 전달받은 변경 이벤트를 릴레이 로그에 기록 후 응답을 보내면 그때 트랜잭션을 완전히 커밋한다.
- 하지만 전송이 보장된 것이지 적용이 보장된 것은 아니다. 
- 또한 서버의 응답을 기다리기 때문에 비동기 방식보다 트랜잭션 처리가 길어질 수 있다.
- 소스 서버는 일정 시간동안 기다리다 응답이 없으면 비동기 방식으로 변경된다. 

동기 복제
- 소스 서버는 레플리카 서버가 소스 서버로부터 전달받은 변경 이벤트를 릴레이 로그에 기록 후 응답을 보내면 그때 트랜잭션을 완전히 커밋한다.
- 하지만 전송이 보장된 것이지 적용이 보장된 것은 아니다. 
- 또한 서버의 응답을 기다리기 때문에 비동기 방식보다 트랜잭션 처리가 길어질 수 있다.
- 반동기 복제에서 일정시간동안 기다리다 비동기 방식으로 전환되는 되지 않는다만 다르다.


### 복제 방식에 따른 분류
리더의 개수에 따라 분류할 수 있다. 리더의 역할은 가장 먼저 쓰기 요청을 받고, 이를 나머지 팔로워들에게 전파하는 것이다

### 리더 기반 복제(leader-based replication)
리더가 1개다. 팔로워는 N개다.<br>
Active-passive replication, master-slave replication이라고도 부른다. <br>
리더 기반 복제에서는 리더 장애와 팔로워 장애가 나타날 수 있으며 이에 따라 적절한 대처 방법도 제시되어 있다.

리더 기반 복제 아키텍처를 쓸 때, 사용자가 실제로 쿼리문을 던지는 곳은 리더 한 군데뿐이다. <br>
새로운 데이터나 변경사항이 들어오면 리더에서 적용하고, 팔로워는 리더를 따라간다. <br>
리더 한 곳에서만 read/write가 모두 일어나고, 나머지 모든 팔로워에서는 read만 일어나는 것이다. <br>
그래서 이를 "읽기 확장 아키텍처"라고도 부른다.


### 다중 리더 복제(multi-leader replication)
리더가 여러개다. 팔로워도 N개다.<br>
좀 더 복잡하다. <br>
리더 기반 복제 방식과 차이점을 비교해놓았다.<br> 
리더 기반 복제와 비교했을 때 다중 리더 복제의 가장 대표적인 위험성은 쓰기 충돌이다. <br>
리더 기반 복제에서는 쓰기 작업이 일어나는 곳이 1곳인 반면 다중 리더 복제에서는 쓰기 작업을 할 수 있는 리더가 여러개이기 때문이다.

다중 리더 복제를 사용하는 사례로는 데이터 센터가 여러개인 경우, 캘린더나 메모 앱처럼 오프라인 작업이 동기화 되어야 하는 서비스를 만들 때, 실시간 협업 편집 툴을 만들 때 등이 있다.


### 리더 없는 복제(leaderless replication)
리더 없는 복제 방식은 한동안 잊혀졌던 키워드라고 한다. <br>
관계형 데이터베이스 출현 이후 거의 잊혀졌다가 아마존에서 dynamoDB를 만든 뒤로 다시 부활했다. <br>
DynamoDB의 정신을 이어받아 만들어진 데이터베이스가 여러개 있는데 이들을 dynamo style DB라고도 부른다.

여기서도 쓰기 충돌이 일어날 수 있다.<br>
모두가 팔로워이기 때문에 모두가 쓰기 작업을 할 수도 있는 것이다. 하지만 실제로 "모두"가 쓰기 작업을 하면 충돌이 어마어마 할 것이기 때문에 몇 대까지 쓰기 작업을 할 수 있는지를 정해야 한다. <br>
이를 read/write 정족수를 통해 정한다. 이 정족수를 구하는 방식도 있다. <br>
이외에도 읽기 복구, 안티 엔트로피 처리에 대한 내용이 있다.


### 리더가 팔로워에게 "전파"하는 방법
리더의 역할은 write를 수행하고 이를 팔로워에게 전파하는 것이라고 했다. <br>
'전파'라니. 추상적인 단어다. 전파를 구현하는 방식도 여러가지가 있다.

- 쿼리 기반 복제: 리더가 수행했던 쿼리문을 그대로 팔로워에게 보낸다. 팔로워는 해당 쿼리문을 수행한다.
  - 장점: 리더와 팔로워 간 전송되는 데이터 크기(=쿼리문의 크기)가 작다.
  - 단점: 쓰기 지연이 발생한다. 즉, 리더쪽에서 수행하는데 오래 걸린 쿼리문은 팔로워에서도 똑같이 오래 걸린다.
- 쓰기 전 로그 배송: 데이터베이스에서 쓰기 요청을 받으면 최적화를 위해 로그를 남긴다. 리더는 이 로그를 보고 디스크에 데이터를 저장하고, 동시에 팔로워에게 보낸다.
- 논리적(row 기반) 로그 복제: 위 방식과 비슷하지만, 복제 로그를 저장소 엔진 내부와 분리할 수 있다. row 단위마다 로그를 끊어서 팔로워에게 보낸다.
- 트리거 기반 복제: 특정 이벤트가 발생 했을 때마다 테이블 변경 내용을 팔로워에게 보낸다.


### 복제지연과 해결방법
리더의 대기 시간을 비롯해서, 복제 작업이 끝나기 전까지 발생하는 딜레이를 '복제 지연'이라고 한다.

자신이 쓴 내용 읽기: read-after-write consistency(read-your-write) 보장 필요<br>
SNS에서 내 프로필을 편집했다. 리더쪽으로 write 요청이 간다. 리더가 write를 완료했고, 팔로워쪽으로도 변경 내역을 전송했다. 내용이 잘 편집되었는지 보기 위해 다시 내 프로필 화면으로 돌아간다. 이 때, 비동기식 복제 방식을 쓰고 있었다고 생각해보자. 변경이 완료되지 않은 팔로워쪽으로 read 요청이 갔다면 문제가 발생한다.

이 문제는 read-after-write consistency (read-your-write consistency라고도 부른다.)를 보장하면 해결된다. 사용자가 페이지를 재로딩 했을 때 항상 자신이 제출한 모든 갱신을 볼 수 있음을 보장하는 것이다. 다른 사용자에 대해서는 보장하지 않아도 된다.<br>
해결 예시로는
- 자신이 수정할 수 있는 데이터는 모두 리더에서만 읽기. 나머지는 팔로워에서 읽기.
  - 예) 내 프로필 데이터는 모두 리더에서만 읽기. 다른 사람 프로필을 볼 때는 팔로워에서 읽기.
- write 요청을 보낸 후 특정 시간동안은 리더에서만 읽기. 그 이후에는 팔로워에서 읽기.

시간이 거꾸로 가는 현상: monotonic read 보장 필요 <br>
누군가의 게시글에 댓글을 다는 상황을 생각해보자. <br>
내가 단 댓글은 리더 DB에 먼저 전달되어서 저장될 것이다. <br>
리더는 팔로워에게도 댓글 정보를 넘겨준다. 이 때, 팔로워가 2개이고 한쪽 팔로워에게는 빠르게 변동사항이 전달되었지만 다른쪽에는 비교적 느리게 갔다고 생각해보자.<br>
그리고 댓글 정보를 읽을 때 처음에는 빠른 팔로워 DB, 나중에는 비교적 느린 팔로워 DB에게 각각 read 요청을 보낸 상황을 가정해보자.

처음에는 내가 적었던 댓글이 잘 보일 것이다. 새로고침을 눌렀다. <br>
비교적 느린 팔로워 DB에게 read 요청을 보냈는데, 아직 이 팔로워는 내가 적은 댓글 정보 처리를 완료하지 못했다면? 내가 쓴 댓글이 보이지 않게 된다.

자신이 쓴 내용 읽기 문제와의 차이점은 '저장 내역을 한 번이라도 본 적이 있다'는 점이다.<br> 
분명히 내가 쓴 댓글을 잘 확인했다. 그런데 새로고침을 하니 내 댓글이 사라지고 마치 시간이 거꾸로 간 것처럼 느껴지는 것이다.<br>
이런 현상을 막기 위해서는 '단조 읽기'라고 번역되는 monotonic read를 보장해야 한다.<br>
이전에 새로운 데이터를 읽은 후에는 예전 데이터를 읽지 않게 하는 것이다.<br> 
예를 들어, 각 사용자별로 무조건 하나의 팔로워 DB만 접근하도록 구현하는 방법이 있다.

인과성 위반 우려: consistent prefix read 보장 필요<br> 
꽤 복잡한 이유로 인해, 쿼리를 전송한 순서가 꼬일 수 있다.<br>  
실제 변경 요청은 query A -> query B 순서로 들어갔지만 리더와 팔로워 간 지연이 일어나면서 실제로 데이터를 보는 사람에게는 마치 B -> A 순서로 보일 수 있다는 것이다.

이 현상을 막기 위해서는 consistent prefix reads가 필요하다.<br> 
일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자도 같은 순서로 쓰여진 내용을 보게 됨을 보장하는 것이다. <br>

[출처](https://velog.io/@broccolism/%EB%B6%84%EC%82%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B1%B8%EC%9D%8C%EB%A7%88-%EB%96%BC%EA%B8%B0-%EB%B3%B5%EC%A0%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%91%EC%8B%AC-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%A4%EA%B3%84-5%EC%9E%A5) : 
https://velog.io/@broccolism/%EB%B6%84%EC%82%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B1%B8%EC%9D%8C%EB%A7%88-%EB%96%BC%EA%B8%B0-%EB%B3%B5%EC%A0%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%91%EC%8B%AC-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%A4%EA%B3%84-5%EC%9E%A5


## 데이터베이스 파티셔닝(Partitioning)
### 배경
- 서비스의 크기가 점점 커지고 DB에 저장하는 데이터의 규모 또한 대용량화 되면서, 기존에 사용하는 DB 시스템의 용량(storage)의 한계와 성능(performance)의 저하 를 가져오게 되었다.
- 즉, VLDB(Very Large DBMS)와 같이 하나의 DBMS에 너무 큰 table이 들어가면서 용량과 성능 측면에서 많은 이슈가 발생하게 되었고, 이런 이슈를 해결하기 위한 방법으로 table을 ‘파티션(partition)’이라는 작은 단위로 나누어 관리하는 ‘파티셔닝(Partitioning)’기법 이 나타나게 되었다.
- ‘파티셔닝(Partitioning)’기법을 통해 소프트웨어적으로 데이터베이스를 분산 처리하여 성능이 저하되는 것을 방지하고 관리를 보다 수월하게 할 수 있게 되었다.

### 개념
- 논리적인 데이터 element들을 다수의 entity로 쪼개는 행위를 뜻하는 일반적인 용어
- 즉 큰 table이나 index를, 관리하기 쉬운 partition이라는 작은 단위로 물리적으로 분할하는 것을 의미한다.
  - 물리적인 데이터 분할이 있더라도, DB에 접근하는 application의 입장에서는 이를 인식하지 못한다.

### 목적
1. 성능(Performance)
- 특정 DML과 Query의 성능을 향상시킨다.
- 주로 대용량 Data WRITE 환경에서 효율적이다.
- 특히, Full Scan에서 데이터 Access의 범위를 줄여 성능 향상을 가져온다.
- 많은 INSERT가 있는 OLTP 시스템에서 INSERT 작업을 작은 단위인 partition들로 분산시켜 경합을 줄인다.
2. 가용성(Availability)
- 물리적인 파티셔닝으로 인해 전체 데이터의 훼손 가능성이 줄어들고 데이터 가용성이 향상된다.
- 각 분할 영역(partition별로)을 독립적으로 백업하고 복구할 수 있다.
- table의 partition 단위로 Disk I/O을 분산하여 경합을 줄이기 때문에 UPDATE 성능을 향상시킨다.
3. 관리용이성(Manageability)
- 큰 table들을 제거하여 관리를 쉽게 해준다.


### 장단점
장점
- 관리적 측면 : partition 단위 백업, 추가, 삭제, 변경
  - 전체 데이터를 손실할 가능성이 줄어들어 데이터 가용성이 향상된다.
  - partition별로 백업 및 복구가 가능하다.
  - partition 단위로 I/O 분산이 가능하여 UPDATE 성능을 향상시킨다.
- 성능적 측면 : partition 단위 조회 및 DML수행
  - 데이터 전체 검색 시 필요한 부분만 탐색해 성능이 증가한다.
    - 즉, Full Scan에서 데이터 Access의 범위를 줄여 성능 향상을 가져온다.
    - 필요한 데이터만 빠르게 조회할 수 있기 때문에 쿼리 자체가 가볍다.

단점
- table간 JOIN에 대한 비용이 증가한다.
- table과 index를 별도로 파티셔닝할 수 없다.
  - table과 index를 같이 파티셔닝해야 한다.


### 파티셔닝의 종류
#### 수평(horizontal) 파티셔닝
하나의 테이블의 각 행을 다른 테이블에 분산시키는 것이다.

개념 <br>
- 샤딩(Sharding) 과 동일한 개념
- 스키마(schema)를 복제한 후 샤드키를 기준으로 데이터를 나누는 것을 말한다.
- 즉, 스키마(schema)가 같은 데이터를 두 개 이상의 테이블에 나누어 저장하는 것을 말한다.

특징<br>
- 퍼포먼스, 가용성을 위해 KEY 기반으로 여러 곳에 분산 저장한다.<br>
- 일반적으로 분산 저장 기술에서 파티셔닝은 수평 분할을 의미한다.<br>
- 보통 수평 분할을 한다고 했을 때는 하나의 데이터베이스 안에서 이루어지는 경우를 지칭한다.

예시
1. 고객의 데이터베이스를 CustomerId를 샤드키로 사용하여 샤딩하기로 하자.
    - 0 ~ 10000 번 고객의 정보는 하나의 샤드에 저장하고 10001 ~ 20000 번 고객의 정보는 다른 샤드에 저장한다.<br>
    - DBA는 데이터 엑세스 패턴과 저장 공간 이슈(로드의 적절한 분산, 데이터의 균등한 저장)를 고려하여 적절한 샤드키를 결정한다.<br>
2. 같은 주민 데이터를 처리하기 위해 스키마가 같은 ‘서현동주민 테이블’과 ‘정자동주민 테이블’을 사용하는 것을 말한다.
    - 인덱스의 크기를 줄이고, 작업 동시성을 늘리기 위한 것이다.

장단점
- 장점
  - 데이터의 개수를 기준으로 나누어 파티셔닝한다.
  - 데이터의 개수가 작아지고 따라서 index의 개수도 작아지게 된다. 자연스럽게 성능은 향상된다.
- 단점
  - 서버간의 연결과정이 많아진다.
  - 데이터를 찾는 과정이 기존보다 복잡하기 때문에 latency가 증가하게 된다.
  - 하나의 서버가 고장나게 되면 데이터의 무결성이 깨질 수 있다. 


#### 수직(vertical) 파티셔닝
테이블의 일부 열을 빼내는 형태로 분할한다.

개념
- 모든 컬럼들 중 특정 컬럼들을 쪼개서 따로 저장하는 형태를 의미한다.
- 스키마(schema)를 나누고 데이터가 따라 옮겨가는 것을 말한다.
- 하나의 엔티티를 2개 이상으로 분리하는 작업이다.

특징
- 관계형 DB에서 3정규화와 같은 개념으로 접근하면 이해하기 쉽다.
- 하지만 수직 파티셔닝은 이미 정규화된 데이터를 분리하는 과정이다.

예시
- 한 고객은 하나의 청구 주소를 가지고 있을 수 있다. <br>
그러나 데이터의 유연성을 위해 다른 데이터베이스로 정보를 이동하거나 보안의 이슈 등을 이유로 CustomerId를 참조하도록 하고 청구 주소 정보를 다른 테이블로 분리할 수 있다.

장단점
- 장점
  - 자주 사용하는 컬럼 등을 분리시켜 성능을 향상시킬 수 있다.
  - 한 테이블을 SELECT하면 결국 모든 컬럼을 메모리에 올리게 되므로 필요없는 컬럼까지 올라가서 한 번에 읽을 수 있는 ROW가 줄어든다.<br> 
  이는 I/O 측면에서 봤을 때 필요한 컬럼만 올리면 훨씬 많은 수의 ROW를 메모리에 올릴 수 있으니 성능상의 이점이 있다.
  - 같은 타입의 데이터가 저장되기 때문에 저장 시 데이터 압축률을 높일 수 있다.

### 파티셔닝의 분할 기준
데이터베이스 관리 시스템은 분할에 대해 각종 기준(분할 기법)을 제공하고 있다. 분할은 ‘분할 키(partitioning key)’를 사용한다.

1. 범위 분할 (range partitioning)
분할 키 값이 범위 내에 있는지 여부로 구분한다.
예를 들어, 우편 번호를 분할 키로 수평 분할하는 경우이다.
2. 목록 분할 (list partitioning)
값 목록에 파티션을 할당 분할 키 값을 그 목록에 비추어 파티션을 선택한다.
예를 들어, Country 라는 컬럼의 값이 Iceland , Norway , Sweden , Finland , Denmark 중 하나에 있는 행을 빼낼 때 북유럽 국가 파티션을 구축 할 수 있다.
3. 해시 분할 (hash partitioning)
해시 함수의 값에 따라 파티션에 포함할지 여부를 결정한다.
예를 들어, 4개의 파티션으로 분할하는 경우 해시 함수는 0-3의 정수를 돌려준다.
4. 합성 분할 (composite partitioning)
상기 기술을 결합하는 것을 의미하며, 예를 들면 먼저 범위 분할하고, 다음에 해시 분할 같은 것을 생각할 수 있다.
컨시스턴트 해시법은 해시 분할 및 목록 분할의 합성으로 간주 될 수 있고 키 공간을 해시 축소함으로써 일람할 수 있게 한다.

[출처](https://gmlwjd9405.github.io/2018/09/24/db-partitioning.html) : 
https://gmlwjd9405.github.io/2018/09/24/db-partitioning.html



## 캐싱(Cache)
Cache는 데이터나 값을 저장하는 임시 저장소로, 데이터를 더 빠르고 효율적으로 액세스할 수 있게 해준다.
- 원본 데이터 접근보다 빠르다.
- 같은 데이터를 반복적으로 접근하는 상황에서 사용하기에 알맞다.
- 잘 변하지 않는 데이터일수록 더 효율적이다.


추상적인 웹 서비스 구조 (클라이언트 - 웹 서버 - DB)<br>
클라이언트가 웹 서버에 접속하고 요청을 보내면 웹 서버가 DB에 데이터를 읽거나 쓰기 작업을 요청한다.<br>
DB도 사실 내부용 캐시가 있지만 캐시 용량이 Memory 사이즈보다 커지면 당연히 Disk를 사용해야 한다. <br>
쿼리 결과를 내부적 캐시에 담고 있는데 여러가지 요청을 처리하다 보면 기존에 있던 캐시를 날리고 디스크에서 새로 읽어야 하는 순간이 온다. <br>
그래서 디스크에 접근할 때마다 속도가 굉장히 느려질 수 있다. 

Redis로 캐시로 사용할 때 어떻게 배치할 것이냐는 캐싱 전략이 필요하다. <br>
 - Redis: Key, Value 구조의 비정형 데이터를 저장하고 관리하기 위한 오픈 소스 기반의 비관계형 데이터 베이스 관리 시스템 (DBMS)입니다.

데이터베이스, 캐시, 메세지 브로커로 사용되며 인메모리 데이터 구조를 가진 저장소입니다.
이에 따라 성능에 영향을 끼치기 때문에 상황(데이터 유형, 데이터 액세스 패턴)에 맞게 적절한 전략을 사용해줘야 한다.

시스템이 많이 작성하는데 덜 자주 읽습니까? (ex. 시간 기반 로그)<br>
데이터를 한번 쓰고 여러 번 읽습니까? (ex. 사용자 프로필)<br>
반환되는 데이터는 항상 고유합니까? (ex. 검색어)<br>
 
모바일 게임용 Top-10 리더보드 시스템의 캐싱 전략과 사용자 프로필을 집계하고 반환하는 서비스의 캐싱 전략은 많이 다르다. <br>
올바른 캐싱 전략을 선택하는 것이 성능 향상의 핵심이다. 이 글에서 알아볼 캐시 전략은 다음 총 5가지이다.

1. Look-Aside(Cache-Aside) 읽기 전략
2. Read-Through 읽기 전략
3. Write-Around 쓰기 전략
4. Write-Through 쓰기 전략
5. Write-Back 쓰기 전략


### Look-Aside 읽기 전략 (Lazy Loading)
Look-Aside는 앱에서 데이터를 읽는 전략이 많을 때 사용하는 전략이다.<br> 
이 구조는 Redis를 캐시로 쓸 때 가장 일반적으로 사용하는 방법이다. <br>
캐시는 찾는 데이터가 없을 때 DB에 직접 조회해서 입력되기 때문에 Lazy Loading이라고 한다.
- 이 방식은 가장 범용적이며 읽기 요청이 많은 경우에 적합하다. 이 구조는 Redis가 다운되더라도 바로 장애로 이어지지 않고 DB에서 데이터를 가져올 수 있다는 장점이 있다. 
- 그런데 만약 캐시에 많은 커넥션이 붙어있는 상태에서 다운이 발생하면 동시에 DB로 그 커넥션이 다 붙기 때문에 갑자기 DB 부하가 많이 몰릴 수 있다.

Look-Aside 전략을 사용할 때 가장 일반적인 쓰기 전략은 DB에 직접 쓰는 Write-Around 쓰기 전략이다. <br>
이 경우 캐시와 DB의 데이터가 일치하지 않을 수 있다. <br>
해결하기 위해 TTL을 사용하고 TTL이 만료될 때 까지는 변경되지 않은 캐시 데이터를 계속 제공한다. <br>
데이터 최신성을 보장해야 하는 경우에는 캐시 entry를 무효화하거나 더 적절한 쓰기 전략(Cache를 거친 쓰기 전략)을 이용해야 한다.

과정
1. 앱은 데이터를 찾을 때 캐시를 먼저 확인한다.
2. 캐시에 데이터가 있으면 해당 데이터를 읽어오는 작업을 반복한다.
3. 만약 Redis에 해당 키가 존재하지 않는다면 (Cache miss) 앱은 DB에 접근해서 데이터를 직접 가지고 온 뒤 다시 Redis에 저장하는 과정을 거친다. 그래서 동일 데이터에 대한 후속 읽기 결과 Cache Hit이 된다.
![alt text](/images/look-aside.png)


### Read-Through 읽기 전략
Read-Through 전략은 데이터를 읽을 때 캐시로만 데이터를 읽어온다. <br>
만약 Cache Miss가 발생하면 DB에서 해당 데이터를 캐시에 바로 저장한다. <br>
즉 캐시는 앱과 DB 중간에 위치해 앱은 캐시만 바라보게 되고 DB는 캐시만 바라보게 된다. <br>
항상 첫 요청은 항상 Cache Miss가 발생하여 데이터가 로딩된다.
- 뉴스 기사 읽기와 같이 동일한 데이터가 여러 번 읽기 요청이 되는 경우에 적합하다. 디스크 읽기 비용을 절약할 수 있다. 
- 첫 요청은 항상 Cache Miss가 발생하여 데이터가 로딩된다.
- Look-Aside와 다른 점은 읽기에 대한 앱의 관점이다. <br>
Look-Aside의 경우 Cache Miss가 나면 앱이 직접 DB에 데이터를 조회한 반면, Read-Through는 캐시에서 DB에 데이터를 직접 조회하여 로드한다. <br>
그리고 Read-Through는 캐시의 데이터 모델과 DB 데이터 모델이 다를 수 없다.

과정
1. 앱은 모든 데이터를 캐시로만 읽어온다.
2. Cache Miss가 발생한 경우 캐시에서 직접 DB 데이터를 읽어온다. 
![alt text](/images/read-through.png)


### Cache Warming - 데이터 미리 캐싱해두기
Look-Aside에서 캐시가 다운되면 다시 새로운 캐시를 투입해야 하고 DB에 새로운 데이터를 넣으면 커넥션은 자연스레 DB로 몰리게 된다. 이러한 경우 초기에 Cache Miss가 엄청 발생해서 성능 저하가 올 수 있다. 매번 첫 요청에 Cache Miss가 발생하는 Read-Through도 마찬가지이다.

이럴 때는 캐시로 미리 데이터를 밀어넣어주는 Cache Warming 작업을 해주면 된다. 실제로 실무에서는 특정 이벤트 상품 오픈 전 해당 상품의 조회수가 몰릴 것을 대비해 상품 정보를 미리 DB에서 캐시로 올려주는 작업을 처리한다고 한다. 
![alt text](/images/cache_warming.png)


###  Write-Through 쓰기 전략
이는 Read-Through와 같다. Write-Through 전략은 DB에 데이터를 저장할 때 먼저 캐시에 기록된 다음 DB에 저장되는 방식이다.
- 캐시는 항상 최신 정보를 가지고 있고 DB와 동기화되어 데이터 일관성을 보장한다는 장점이 있지만
- 저장할 때 마다 두 단계 스텝(앱 → Redis → DB)을 거쳐야 하기 때문에 추가 쓰기 시간이 발생하여 상대적으로 느리다는 단점이 있다. 그리고 저장하는 데이터가 재사용하지 않을 수도 있는데 무조건 캐시에 넣는 것은 리소스 낭비이다.

따라서 이렇게 데이터를 저장할 때에는 얼마 동안만 캐시에 보관하고 있겠다는 TTL을 설정해주는 것이 좋다

과정
1. 앱은 모든 데이터를 캐시에 저장한 후 DB에 저장한다.
![alt text](/images/write-through.png)
Read-Through 캐시와 함께 사용하면 Read-Through의 모든 이점을 얻을 수 있고 데이터 일관성도 보장되어 캐시 무효화 기술을 사용하지 않아도 된다.

그런데 만약 캐시 전략을 잘못 조합하면 성능이 안좋아진다.<br> 
예를 들어 실시간 로그를 기록하는 시스템에서 Read-Through / Write-Through 전략을 사용한다면 자주 읽지도 않는 데이터가 캐시에 적재되기 때문에 리소스 낭비가 발생하게 된다.<br>
이러한 경우에는 Read-Through / Write-Around 전략을 사용하는 게 적합하다. 

### Write-Around 쓰기 전략
Write-Around 전략은 DB에만 데이터를 저장하고 읽은 데이터만 캐시에 저장하는 방식이다. <br>
일단 모든 데이터는 DB에 저장되고 Cache Miss가 발생한 경우에만 DB에서 캐시로 데이터를 끌어오게 된다.
- 자주 읽히지 않는 데이터는 캐시에 로드되지 않으니 리소스를 절약할 수 있다.
- 그러나 캐시 내의 데이터와 DB내의 데이터가 다를 수 있다는 단점이 있다. (ex. 캐시에 이미 로드된 데이터를 수정할 경우)

과정
1. 앱은 모든 데이터를 DB에 저장한다.
2. Cache Miss가 발생한 경우에만 DB에서 캐시로 데이터를 저장한다.
![alt text](/images/write-around.png)
그래서 Write-Around는 데이터가 한 번 쓰여지고 덜 자주 읽히거나 읽지 않는 상황에서 좋은 성능을 제공할 수 있다. <br>
이 경우 읽기 전략은 크게 상관없다. (Read-Through나 Look-Aside와 모두 결합 가능)
- 실시간 로그
- 채팅방 메시지


### Write-Back 쓰기 전략
Write-Back 전략은 쓰기 작업을 캐시에 먼저 저장했다가 특정 시점마다 DB에 저장하는 방식이다. <br>
디스크 기반 DB로 치면 데이터를 굉장히 많이 써야되기 때문에 무조건 디스크에 저장해야 하는 상황에서 주로 사용한다. <br>
매번 디스크 쓰기를 실행하면 시간이 오래 걸리기 때문에 캐시에 저장해두었다가 묶음으로 디스크 쓰기 작업을 실행해주는 것이다.
- 쓰기가 많은 경우에 적합하다. DB 디스크 쓰기 비용을 절약할 수 있다. 그리고 특정 시점에만 DB에 쓰기 요청을 하기 때문에 DB 오류에도 탄력적이다.
- 바꿔서 생각해보면 데이터를 캐시에 모두 모아뒀다가 DB에 옮기기 때문에 도중 캐시에 장애가 발생하면 데이터 유실이 크게 발생할 수 있다.

대부분의 RDB 스토리지 엔진 내부에는 Write-Back 캐시 기능을 갖고 있다. 쿼리는 먼저 메모리에 기록되다가 특정 시점에 한 번에 Disk에 flush된다. 

과정
1. 앱은 모든 데이터를 캐시에 저장한다.
2. 특정 시점이 되면 캐시에 저장된 데이터를 DB에 저장한다.
3. 그렇게 DB에 저장된 데이터는 캐시에서 삭제해준다.
![alt text](/images/write-back.png)
Write-Back은 Read-Through와 결합하면 가장 최근 업데이트되고 액세스 된 데이터를 항상 캐시에서 사용할 수 있다.

[출처](https://loosie.tistory.com/800) :
https://loosie.tistory.com/800

<br><br>

## 배치 프로그램(batch processing)
일괄 처리(batch processing)란 컴퓨터 프로그램 흐름에 따라 순차적으로 자료를 처리하는 방식<br>
배치 프로그램 이란 한꺼번에 일괄적으로 대량 데이터 건을 처리하는 것 (보통 정해진 특정한 시간에 실행)

특징
- 대량의 데이터를 처리
- 특정 시간에 실행
- 일괄적으로 처리

Batch 작업은 사용자에게 빠른 응답이 필요하지 않은 서비스에 적용할 수 있다. <br>
작업을 실행한 특정 시간 이후에는 자원을 거의 소비하지 않는 것이 특징이다. <br>
Batch에 반대되는 방식은 OLTP 방식으로 사용자와 DB가 지속적으로 상호작용하는 경우에 OLTP 방식으로 개발되어야 한다.

### 배치 프로세싱의 장점
- 속도 및 비용 절감 <br>
배치 프로세싱은 대부분 자동화되어 있기 때문에 수동 개입이 필요하지 않다. <br>
자동화는 운영 비용을 줄이고 트랜잭션 및 데이터 처리 속도를 높인다. 조직은 필요한 경우 데이터가 처리되는 순서의 우선 순위를 지정할 수 있습니다.

- 정확성<br>
프로세스에서 인력의 개입을 없앰으로써 인적 오류가 없어 시간과 비용을 절약하고 결과적으로 데이터의 정확성을 높이고 최종 사용자를 더 만족스럽게 할 수 있다.

- 오프라인 기능<br>
배치 프로세싱 시스템은 오프라인으로 작동한다.<br> 
하루가 끝나도, 이 프로세싱은 여전히 작동하고 있다. <br>
관리자는 프로세스가 시작되는 시점을 제어하여 시스템을 압도하고 일상적인 활동을 방해하지 않도록 할 수 있다.

- 한 번 설정 후 자동 수행<br>
배치 프로세싱 시스템은 이미 마련되면 자동으로 작동한다. <br>
로그인하여 아무것도 확인하거나 조정할 필요가 없다. <br>
문제가 있는 경우 해당 직원에게 예외 알림이 전송됩니다. 그리고 관리자가 신뢰할 수 있는 완전히 수동적인 솔루션이다.

- 단순함 유지<br>
지속적인 시스템 지원, 추가 데이터 입력 또는 특수 소프트웨어가 필요하지 않다. <br>
시스템이 가동되고 실행되면 유지 관리가 필요 없으며 데이터 처리를 위한 진입 장벽이 낮은 솔루션이다.

- 머신 러닝 및 인공 지능을 위한 정확한 데이터<br>
인공 지능의 가장 큰 문제 중 하나는 저품질 데이터이다. <br>
데이터 사이언티스트는 데이터를 정리하고 오류와 불일치를 제거하는 데 많은 시간을 할애하게 된다. <br>
배치 프로세싱은 자동화된 특성으로 인해 데이터 오류를 완전히 방지한다. <br>
이상이 발견되면 즉시 플래그를 지정하여 신속하게 해결할 수 있다. <br>
최종 결과는 정확한 예측을 생성할 수 있게 하는 매우 정확한 데이터이다.

- 기존 컴퓨터 시스템의 사용 개선<br>
시스템 수요가 낮은 지점에서 데이터를 처리할 수 있도록 하면 기존 시스템을 최대한 활용할 수 있다. <br>
시스템이 대역폭의 특정 지점에 도달하면 배치 프로세싱이 트리거되거나 자동화될 수 있으므로 새 시스템을 구입할 필요가 줄어들고 기존 리소스가 더 지능적으로 사용된다.


## 스트리밍 데이터 처리 개념
Bounded data vs Unbounded data
- Bounded data : 데이터가 저장되고 더 이상 증가나 변경이 없이 유지되는 데이터
  - ex) 1월 정산 데이터
- Unbounded data : 데이터의 수가 정해져있지 않고 계속해서 추가되는 데이터
  - ex) SNS 타임피드, 증권 거래, 로그…

Event time vs Processing time
- Event time : 이벤트가 발생할 시간
- Processing time : 이벤트가 서버로 전달되고 로직을 수행하여 저장된 시간
- Skew : 이상적으로는 같아야 하지만 중간에 Latency가 발생을 하여 지연이 발생하는데 이를 Skew라고 한다.

Bounded data의 처리 <br>
이미 저장되어 있는 데이터를 처리하기 때문에 별다른 처리 패턴이 필요없이 데이터를 읽어서 한번에 처리해서 저장하면 된다.

### Unbounded data의 처리 <br>
크게 두가지 처리 방식이 있다.
- Fixed Windows <br>
스트리밍으로 들어오는 데이터를 일정 시간 단위로 모은 후, 배치로 처리하는 방식으로 구현이 간단하다는 장점이 있지만, 데이터가 수집 된 후 처리를 시작하기 때문에, 실시간성이 떨어진다. <br>
ex) 10-11시 데이터 수집, 11시-12시 데이터 수집

- Streaming 처리<br>
Unbounded 데이터를 제대로 처리하려면 스트리밍 처리를 하는 것이 좋은데, 스트리밍 처리 방법에는 크게 Time agnostic, Filtering, Inner Join, Windowing 방식등이 있다.<br>
기본적으로 스트리밍 처리에는 Skew가 환경에 따라 변화가 심하여 데이터가 도착하는 시간이 일정하지 않다.

### Streaming 처리 방법
- Time agnostic<br>
시간 속성을 가지지 않은 데이터로 들어오는대로 처리

- Filtering<br>
특정 데이터만 필터링 하여 저장하는 구조

- Inner joins<br>
독립적인 Unbounded data를 비교 매칭하여 값을 구하는 방식, 양쪽 스트림에서 데이터 항상 같은 시간에 도착하는 것이 아니기 때문에, 다음과 같은 매커니즘이 필요

> A 도착 -> B 도착할때까지 버퍼에 저장 -> B 도착 -> 조인하여 결과 저장 -> 버퍼에서 삭제
img

- Approximation algorithms<br>
시급한 분석이 필요한 경우, 전체 데이터를 분석하지 않고 일부만 분석하거나, 대략적인 데이터의 근사값만을 구하는 방법으로 대표적으로 K-means나 Approximate Top-N등이 있다.<br>
ex) VOD에서 최근 10분간 인기있는 비디오 목록, 12시간 동안 가장 많이 팔린 제품

- Windowing : 일정 시간 간격으로 처리하는 방법
  - Fixed Window : 정확하기 일정 시간 단위로 시간 윈도우를 쪼개는 개념
  - Sliding Window : 현재시간으로부터 +- N 시간의 데이터를 특정 시간마다 추출하는 방식
  - Session Window : 사용자가 일정 기간동안 데이터를 보내고 일정시간 동안 데이터 없는 동안을 윈도우로 묶는 개념


#### 시간대별 Window 처리 방식
- Processing time based windowing : 도착한 순서대로 처리해서 저장
- Event time based windowing : Event time을 기준으로 데이터를 처리하는 개념으로 Skew가 발생하는 경우 저장했다가 처리해줘야 하기 때문에 Buffering과 Completeness란 개념이 필요


## 이벤트(Event)
Event : 시스템 내, 외부에서 발생한 주목할 만한 상태의 변화 <br>
[a significant change in state]

Event Driven : 이벤트 주도, 이벤트 기반
architecture : 동작 방식

EDA : 이벤트를 기반으로 하는 아키텍처 설계 방식
EDP : 이벤트를 기반으로 하는 프로그래밍

### 이벤트 드리븐 아키텍쳐
EDA (Event-driven architecture) : <br>
이벤트의 생산, 감지, 소비 및 반응 또는 시스템 상태의 중대한 변화를 지원하는 소프트웨어의 모델 혹은 아키텍처 패러다임

복잡성과 역동성에 가장 효율적으로 대응할 수 있는 모델이다.<br> 
(시시각각 발생하는 이벤트의 생성과 감지, 반응을 중심으로 구축되는 모델이기 때문이다.)

프로그램이 어떤 유저액션(이벤트)에 대한 반응으로 동작하는 패턴이라고 생각된다.

가장 흔하게 예를 들을 수 있는것은 키보드, 마우스로 하는 동작이 이벤트이며, 이러한 이벤트는 또 다른 결과를 가져오고, 이러한 패턴

이벤트 기반 시스템은 이벤트 루프에서 이벤트를 처리하며, 이벤트 루프는 장치로부터 입력이나, 내부경보를 기다리고 있다가 활동이 발생하면, 이벤트를 생성시킨다.<br> 
발생한 이벤트의 데이터를 수집하고, 데이터를 필요한 이벤트 핸들러로 발송한다.

예시) 예매 사이트
축구 경기를 예매 (동시간대)
고객 A : A-1 좌석을 결제 요청 -> (해당 좌석이 실제 예매 가능인지 파악) -> 예매 완료,
고객 B : A-1 좌석을 결제 요청 -> (해당 좌석이 실제 예매 가능인지 파악) -> 예매 진행중 -> 결제 불가 처리 (트렌젝션, rollback)

이렇게 다수의 사용자가 이벤트를 발생시키고, 이러한 결과는 또 다른 사용자 혹은 시스템을 실시간으로 변경을 발생시킨다.

데이터 무결성 (data integrity): 데이터는 완전한 수명 주기를 거치며 데이터의 정확성과 일관성을 유지하고 보증하는 것을 말한다.

일반적으로 EDA는 3가지 필수 요소로 구성된다.

- Event Emitters : 시스템 내에서 발생하는 이벤트를 수집, 이벤트를 받아 채널로 전달
- Event channels : 특정 소비자에게 이벤트를 전달, 일정 수준의 전처리 수행 후 소비자에게 전달
- Event Consumers:

이벤트 채널은 두 가지 토폴리지가 존재한다.

- 중재자 토폴리지
- 브로커 토폴리지

중재자 토폴리지는 단일 큐와 이벤트 중개자를 사용하여 이벤트를 처리, 일반적으로 이벤트 처리에 여러 단계가 필요할 경우 사용 <br>
브로커 토폴리지는 이벤트 플로우가 단순한, 중앙 집중식 토폴리지, 중재자와는 달리 이벤트 큐가 없다.


### 이벤트 드리븐 프로그래밍
이벤트 기반 프로그래밍 (EDP: Event-driven programming)

과거에는 순차적, 절차적 프로그래밍이 일반적이었다. <br>
모든 프로그램의 흐름을 시간의 흐름대로 순서대로 정의하고 해석하였다. <br>
현재도 비슷한 패턴은 동일

콘솔 프로그래밍 (Single-Tasking) 에서 사용자의 입력을 받는 타이밍이 있고, 해당 입력시 인터럽트가 발생하여도 경우의 수가 적었다.<br>
이 말을 정리하면, 흐름을 예측할 수 있었고, 예측 불가한 예외는 소수였다고 볼 수 있다.<br> 따라서 순차적 프로그래밍이 적합하였다.

하지만 현대적 프로그램 환경(윈도우 프로그래밍 Multi-Tasking : GUI 환경)에서는 이 패턴은 잘 맞지 않았다. <br>
현대의 환경에서는 흐름을 예측하기가 매우 어렵다. <br>
(이벤트가 몹시 다양하게 발생 : 마우스, 키보드 타이밍과 값 등 예외가 매무 많다.)<br>
이러한 상황에서도 순차적 프로그래밍은 가능하다. <br>
모든 이벤트를 예외로 처리하는 방식으로 적용 가능하다. 실제로 Win32 API가 이런식으로 구현되었다.

싱글 테스킹서는 한번에 하나의 프로그램만을 실행하고, 멀티 테스킹에서는 동시에 여러 프로그램이 실행된다. <br>
콘솔은 자기 자신만을 고려하여 프로그램을 작성하면 되지만, 윈도우는 동시에 수행되는 다른 프로그램을 고려하여 개발을 진행해야 한다. <br>
이런 부분을 운영체제가 알아서 처리해주며, 그러한 규칙을 정한것이 EDP이다.

이벤트 -> 이벤트 처리
개발자는 메세지를 처리하는 함수를 작성하고, 윈도우를 생성하여 출력만 진행하면 된다.

컴퓨터 프로그램 중 특정 이벤트에 반응하여 동작을 변경하는 방식을 Event-driven 방식이라고 한다.

프로그램은 이벤트를 처리하기 위한 이벤트 핸들러를 가지며, 이벤트 루프라는 곳에서 이를 처리한다.
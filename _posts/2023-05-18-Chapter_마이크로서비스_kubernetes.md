---
title:  "kubernetes"
excerpt: "DevOps 부트캠프 Section 3"

categories:
  - Blog
tags:
  - [Blog, DevOps]

toc: true
toc_sticky: true
 
date: 2023-05-18
last_modified_at: 2023-05-18
---
# 쿠버네티스
쿠버네티스란 컨테이너화된 애플리케이션의 배포, 확장 및 관리를 자동화하는 오픈 소스 시스템이다.

1주일에 수십억 개의 컨테이너를 생성하는 Google이 내부 배포시스템으로 사용하던 'borg'를 기반으로 2014년 프로젝트를 시작했고, 여러 커뮤니티의 아이디어와 좋은 사례들을 모아 빠르게 발전하였다. <br>
이후 Google이 CNCF(Cloud Native Computing Foundation)에 코드를 기부함으로써, 쿠버네티스는 오픈 소스 프로젝트가 되었습니다. 

쿠버네티스는 단순한 컨테이너 플랫폼이 아닌 마이크로서비스, 클라우드 플랫폼을 지향하고, 컨테이너로 이루어진 것들을 손쉽게 담고 관리할 수 있는 그릇 역할을 한다. <br>
서버리스, CI/CD, 머신러닝 등 다양한 기능이 쿠버네티스 플랫폼 위에서 동작한다. 

<br><br>

### 필요성
쿠버네티스를 사용하면 컨테이너화된 애플리케이션 환경(Containerized Application)을 탄력적으로 실행할 수 있게 된다.

프로덕션 환경에서는 애플리케이션을 실행하는 컨테이너를 관리하고 가동 중지 시간이 없는지 확인해야 한다. <br>
예를 들어, 컨테이너가 다운된다면 다른 컨테이너를 다시 시작하여 가동 중지 시간(다운 타임)을 최소화하여야 한다.

이러한 문제를 시스템에 의해 관리되도록 하는 것이 쿠버네티스의 역할이다.

<br><br>

### 기능
- 서비스 디스커버리와 로드 밸런싱 - DNS 이름을 사용하거나 자체 IP 주소를 사용하여 컨테이너를 노출
- 스토리지 오케스트레이션 - 로컬 저장소, 공용 클라우드 공급자 등과 같이 원하는 저장소 시스템을 자동으로 탑재 
- 자동화된 롤아웃과 롤백 - 원하는 상태를 서술하고 현재 상태를 원하는 상태로 설정한 속도에 따라 변경 가능 
- 자동화된 빈 패킹 - 각 컨테이너가 필요로 하는 CPU와 메모리(RAM)를 제공 
- 자동화된 복구(self-healing) - 실패한 컨테이너를 다시 시작하고, 컨테이너를 교체
- 시크릿과 구성 관리 - 암호, OAuth 토큰 및 SSH 키와 같은 중요한 정보를 저장하고 관리 


## Desired state
![alt text](/images/disired_state.png)

쿠버네티스는 원하는 상태(Desired state)를 계속 체크하고 문제가 있다면 자동으로 조치한다.<br>
원하는 상태(Desired state)란 관리자가 바라는 환경을 의미하고, 좀 더 구체적으로는 얼마나 많은 웹서버가 구동되고 있으면 좋은지, 몇 번 포트로 서비스하기를 원하는 등을 말한다. 

쿠버네티스는 복잡하고 다양한 작업을 하지만 자세히 들여다보면, 현재 상태를 모니터링하면서 관리자가 설정한 원하는 상태를 유지하려고 내부적으로 작업을 하는 단순한 로직을 가지고 있다. 

쿠버네티스에서는 YAML 또는 JSON 파일을 사용해, 원하는 애플리케이션 상태(Desired State)에 대해 명시적으로 설정할 수 있다. 

작성을 완료하고 나면, 쿠버네티스가 작성 파일에 정의된 사양에 따라 컨테이너의 라이프사이클을 관리한다. <br>
쿠버네티스를 사용하면 시스템으로 컨테이너 기반 애플리케이션 및 서비스의 설정, 라이프사이클, 스케일 등을 관리할 수 있게된다.


### 설정 가능한 범위
쿠버네티스에서는 다양한 요소들을 설정할 수 있다. 

쿠버네티스에서는 Pod를 배포할 때, 컨테이너에 필요한 각 리소스의 양을 선택적으로 지정할 수 있다. <br>
일반적으로는 CPU, 메모리(RAM) 그리고 다양한 것들을 제한할 수 있다.

YAML 파일에 컨테이너에 대한 리소스 제한(limit)을 지정하면, 설정한 제한보다 많은 리소스를 사용할 수 없도록 해당 제한을 적용한다. <br>
그뿐만 아니라, 해당 시스템 리소스의 최소 요청량 또한 설정할 수 있다. 



### 쿠버네티스의 구성
![alt text](/images/kubernetes.png)
쿠버네티스는 여러 개의 노드(예를 들어, 가상서버/Virtual Machine)로 구성된 클러스터로 이루어져 있다.

위의 그림에서 Node는 하나의 VM(Virtual Machine)을 의미한다. <br>
쿠버네티스는 컨테이너화 된 애플리케이션을 실행하는 Worker Node와 그러한 Worker Node를 관리하는 Master Node로 구성되어 있다.

이때 Worker Node와 Master Node는 다수로 이루어질 수 있으며, 쿠버네티스를 사용하기 위해서는 최소 1개의 Worker Node를 보유해야한다. 


### master node(control plane)
Master Node에는 클러스터에 관한 전반적인 결정을 수행하고, 이벤트를 감지하고 반응하는 역할을 해야한다. 

Master Node는 다음과 같은 그림으로 구성되어 있다. 
![alt text](/images/master_node.png)

Master Node에는 기본적으로 다음 컴포넌트들을 통해 역할을 수행한다. 

- kube-apiserver: 모든 요청을 처리하는 역할<br>
모든 클러스터 관리의 입구로서, 명령을 내릴 수 있는 관문이다. <br>
실제로 쿠버네티스에서 제공되는 UI나 CLI등에서 클러스터 관리를 위해 뭔가 명령을 내리면 API가 호출된다.
- kube-controller-manager: 다양한 컨트롤러(복제/배포/상태 등)를 관리
- kube-scheduler: 상황에 맞게 적절한 Worker Node를 선택
- etcd: 클러스터 내의 데이터를 담는 저장소



### worker node
Worker Node에서는 컨테이너화된 애플리케이션을 동작하고 유지시키는 역할을 한다. 

Worker Node는 다음과 같은 그림으로 구성되어 있다. 
![alt text](/images/worker_node.png)

Worker Node에서는 다음 컴포넌트들을 통해 역할을 수행한다.

- pod: 컨테이너화된 애플리케이션 그룹
- kubelet: 	Node에 할당된 pod의 상태를 체크하고 관리, 다른 노드와 서로 통신하거나 컨테이너를 실행하는 등의 태스크를 실행할 수 있게한다.
- kube-proxy: pod로 연결되는 네트워크를 관리


## 쿠버네티스의 동작 흐름
쿠버네티스에서는 새로운 Pod를 만들기 위한 과정이 다음과 같은 흐름으로 진행된다. 
![alt text](/images/kuber_flow.png)

1. Master Node의 kube-apiserver에 Pod 생성을 요청

2. kube-apiserver는 etcd에 새로운 상태를 저장

3. kube-controller-manager에게 kube-apiserver가 etcd의 상태 변경을 확인하여, 새로운 Pod 생성을 요청

4. kube-controller-manager는 새로운 Pod를 생성(no assign)을 kube-apiserver에 전달하고, 이를 전달받은 kube-apiserver는 etcd에 저장 

5. kube-scheduler는 kube-apiserver에 의해 Pod(no assign)가 확인되면, 조건에 맞는 Worker Node를 찾아 해당 Pod를 할당하기 위해 kube-apiserver는 etcd에 업데이트

6. 모든 Worker Node의 kubelet은 자신의 Node에 할당되었지만, 생성되지 않은 Pod가 있는지 체크하고 있다면 Pod를 생성

7. 해당 Worker Node의 kubelet은 Pod의 상태를 주기적으로 API Server에 전달 

흐름을 보면 각각의 컴포넌트들이 서로 개별적으로 통신하지 않고, API Server를 통해서 통신하는 것을 알 수 있다. 

또한 컴포넌트들은 각기 현재 상태를 체크하고 독립적으로 동작하게된다. 

[reference](https://tech.ktcloud.com/82): https://tech.ktcloud.com/82

## Pod
쿠버네티스의 기본 단위는 Pod(팟)이다. <br>
Pod는 쿠버네티스에서 컨테이너화된 애플리케이션을 실행하는 최소한의 배포 단위이다.

Pod는 일반적으로 하나 이상의 컨테이너로 구성된다.<br> 이 컨테이너들은 동일한 호스트에서 함께 실행되며, 동일한 네트워크 네임스페이스, IP 주소와 포트 범위를 공유한다. <br>
Pod 내의 컨테이너들은 서로 간에 localhost를 통해 통신할 수 있다. <br>
Pod는 하나의 논리적인 호스트로 간주된다.

Pod는 다음과 같은 주요 특징을 가지고 있다:

- 공유 네트워크 네임스페이스: Pod 내의 컨테이너들은 동일한 네트워크 인터페이스를 공유하며, 같은 IP 주소와 포트 범위를 사용한다. <br>
이를 통해 컨테이너 간에 손쉬운 통신이 가능하다.

- 공유 스토리지 볼륨: Pod는 하나 이상의 스토리지 볼륨을 공유할 수 있다. <br>
이를 통해 컨테이너들이 파일 시스템이나 데이터를 공유하고 데이터를 영구적으로 보존할 수 있다.

- 라이프사이클 관리: Pod는 원자적인 개체로서 시작, 정지, 재시작 등의 라이프사이클을 관리할 수 있다.<br> 
여러 컨테이너로 구성된 Pod는 함께 생성되고 삭제되며, 상호 의존적인 관계를 가질 수 있다.

- 스케줄링 단위: 쿠버네티스는 Pod를 최소 스케줄링 단위로 삼아 배포 및 스케일링을 수행한다. <br>
여러 개의 Pod를 생성하고 이를 다수의 노드에 분산하여 실행할 수 있으며, 필요에 따라 Pod의 수를 증가 또는 감소시킬 수 있다.

Pod는 단일 컨테이너 애플리케이션 또는 여러 컨테이너로 구성된 마이크로서비스 애플리케이션 등 다양한 유형의 애플리케이션을 실행하는 데 사용된다.<br> 
또한 Pod 내에서 실행되는 컨테이너는 동일한 호스트 환경을 공유하기 때문에 서로간의 상호작용이 필요한 애플리케이션 구성에 적합하다.



## Deployment
쿠버네티스(Kubernetes) 디플로이먼트(Deployment)는 쿠버네티스에서 애플리케이션을 배포하고 관리하는 리소스 유형이다. <br>
Deployment를 사용하면 애플리케이션을 쿠버네티스 클러스터에 쉽게 배포하고, 롤링 업데이트, 롤백, 스케일링 등을 관리할 수 있다.

Deployment는 다음과 같은 주요 특징을 가지고 있다:

- 애플리케이션 배포: Deployment는 쿠버네티스 클러스터에 애플리케이션을 배포하는 데 사용된다.<br> 
Deployment는 Pod의 템플릿을 정의하고, 원하는 상태에 따라 Pod의 복제본 수를 지정하여 애플리케이션을 실행한다.

- 롤링 업데이트: Deployment는 애플리케이션을 업데이트할 때 롤링 업데이트 전략을 사용할 수 있다.<br>
이전 버전의 Pod을 점진적으로 종료하고 새로운 버전의 Pod을 생성하여 서비스 중단 없이 애플리케이션 업데이트를 수행한다.

- 롤백: Deployment는 업데이트를 롤백하는 데 사용될 수 있다. <br>
이전 버전의 Pod 상태로 되돌려 애플리케이션을 롤백할 수 있으며, 필요한 경우 자동으로 롤백을 수행할 수 있다.

- 스케일링: Deployment는 애플리케이션의 수평 스케일링을 지원한다. <br>
Pod의 복제본 수를 조정하여 애플리케이션의 처리량과 가용성을 조절할 수 있다.

- 상태 관리: Deployment는 애플리케이션의 상태를 모니터링하고 관리할 수 있다. <br>
Pod의 레플리카 상태, 가용성, 이벤트 등을 추적하여 애플리케이션의 정상 작동을 유지한다.

Deployment는 쿠버네티스 YAML 파일을 사용하여 정의되며, 쿠버네티스 클러스터에 배포된다.<br>
Deployment의 정의에서는 애플리케이션의 컨테이너 이미지, 포트, 환경 변수, 리소스 제한 등을 설정할 수 있다. <br>
이러한 Deployment 정의는 쿠버네티스에 의해 해석되어 Pod 및 관련 리소스가 생성되고 관리된다.

쿠버네티스 Deployment는 애플리케이션의 안정적인 배포와 운영을 위한 중요한 리소스이며, 애플리케이션의 생명주기 관리를 간편하게 할 수 있다.


## Service
쿠버네티스(Kubernetes)의 서비스(Service)는 클러스터 내의 애플리케이션에 대한 네트워크 접근성을 제공하는 추상화된 리소스이다. <br>
다른 언어로는 파드들을 통해 실행되고 있는 애플리케이션을 네트워크에 노출(expose)시키는 가상의 컴포넌트다.<br>
서비스는 애플리케이션의 로드 밸런싱, 서비스 디스커버리, 네트워크 이름 관리 등을 담당하여 쿠버네티스 클러스터 내에서 애플리케이션을 안정적으로 운영할 수 있도록 한다.

쿠버네티스 서비스의 주요 특징은 다음과 같다:

- 로드 밸런싱: 서비스는 클러스터 내에서 실행되는 Pod들에 대한 로드 밸런싱을 제공합니다. <br>
여러 개의 Pod 인스턴스가 실행될 때, 서비스는 요청을 여러 Pod들에 분산시켜 부하를 분산시킨다.<br>
이를 통해 애플리케이션의 가용성과 성능을 향상시킬 수 있다.

- 서비스 디스커버리: 서비스는 클러스터 내에서 실행되는 애플리케이션에 대한 동적인 디스커버리를 제공한다. <br>
클러스터 내의 다른 애플리케이션은 서비스를 통해 해당 애플리케이션의 엔드포인트(Endpoint) 정보를 얻을 수 있으며, 이를 사용하여 서비스 간의 통신을 수행할 수 있다.

- 네트워크 이름 관리: 서비스는 고유한 DNS 이름을 할당받는다. <br>
이 DNS 이름을 통해 클러스터 내부에서 서비스에 접근할 수 있으며, Pod들의 IP 주소 변화에 관계없이 일관된 방식으로 서비스에 접근할 수 있다.

- 서비스 유형: 쿠버네티스 서비스는 다양한 유형을 가질 수 있다. <br>
가장 일반적인 유형은 ClusterIP, NodePort, LoadBalancer, ExternalName 등이 있으며, 각각 다른 네트워크 설정 및 접근성을 제공한다.

쿠버네티스 서비스는 애플리케이션의 네트워크 관리를 단순화하고, 다른 리소스들과의 통신을 용이하게 하며, 고가용성과 확장성을 제공한다. <br>


### Health check
쿠버네티스(Kubernetes)에서 헬스 체크(Health Check)는 애플리케이션의 상태를 주기적으로 모니터링하고, 애플리케이션의 가용성을 확인하기 위해 수행되는 메커니즘이다. <br>
헬스 체크는 애플리케이션의 정상 작동 여부를 확인하고, 문제가 발생한 경우 이를 쿠버네티스에 알려줌으로써 클러스터가 이를 처리할 수 있도록 한다.

쿠버네티스에서는 주로 두 가지 유형의 헬스 체크를 사용한다:

Liveness Probe: Liveness Probe는 애플리케이션의 생존 여부를 확인하기 위해 주기적으로 실행된다.<br> 예를 들어, 애플리케이션의 특정 엔드포인트에 HTTP GET 요청을 보내는지, TCP 소켓 연결이 성공적으로 이루어지는지 등을 확인할 수 있다. <br>
Liveness Probe가 실패한 경우, 쿠버네티스는 해당 애플리케이션의 컨테이너를 다시 시작하거나 재시작할 수 있다.

Readiness Probe: Readiness Probe는 애플리케이션이 클라이언트 요청을 처리할 준비가 되었는지를 확인하기 위해 주기적으로 실행된다.<br> 애플리케이션이 준비 상태인 경우, 클라이언트 요청을 처리할 수 있으며, 준비 상태가 아닌 경우에는 클라이언트 요청을 전달하지 않는다. <br>
Readiness Probe를 사용하여 애플리케이션의 부팅 시간, 초기화 과정 등이 완료된 후에만 트래픽을 전달할 수 있다.

#### prob란
애플리케이션의 상태를 확인하기 위해 사용되는 메커니즘이다. <br>
Probe는 주기적으로 실행되는 액션 또는 명령어로, 애플리케이션의 가용성을 모니터링하고 상태를 확인하는 역할을 수행한다. <br>
Probe는 Pod의 스펙(spec)에 정의되며, 컨테이너의 실행 유무, 준비 상태, 시작 상태 등을 확인하는 데 사용된다.

헬스 체크는 Pod 단위로 설정되며, 쿠버네티스의 Deployment, StatefulSet, DaemonSet 등의 리소스에서 지정할 수 있다. <br>
헬스 체크는 HTTP 요청, TCP 소켓 연결, 명령 실행, 자체 정의 스크립트 등 다양한 방식으로 구성할 수 있다. <br>
헬스 체크가 설정된 Pod은 지정된 주기에 따라 헬스 체크가 수행되며, 체크 결과에 따라 Pod의 상태가 변경될 수 있다.



### 인그레스
쿠버네티스(Kubernetes) 인그레스(Ingress)는 클러스터 내의 서비스에 대한 외부 접근을 관리하는 기능이다. <br>
인그레스는 네트워크 계층에서 동작하며, 외부에서 클러스터 내의 서비스로의 트래픽을 경로 기반으로 라우팅하고 로드 밸런싱하는 역할을 수행한다.

인그레스는 다음과 같은 기능을 제공한다:

외부 접근 관리: 인그레스는 클러스터 외부에서 애플리케이션에 접근하기 위한 진입점 역할을 한다.<br> 
인그레스 컨트롤러를 사용하여 클러스터 외부의 로드 밸런서, 리버스 프록시, 라우터 등과 연동하여 외부에서 애플리케이션에 접근할 수 있도록한다.

경로 기반 라우팅: 인그레스는 들어오는 요청의 경로를 기준으로 트래픽을 다른 서비스로 라우팅할 수 있다. <br>
예를 들어, 도메인의 서브패스나 URL 경로를 기준으로 특정 서비스로 요청을 전달할 수 있다. <br>
이를 통해 동일한 IP 주소와 포트를 사용하면서도 여러 개의 애플리케이션을 구동하고, 애플리케이션 간에 트래픽을 분리하고 분배할 수 있다.

로드 밸런싱: 인그레스는 서비스로 들어오는 트래픽을 여러 포드 또는 서비스 인스턴스로 분산시켜 로드 밸런싱을 수행할 수 있다. <br>
이를 통해 애플리케이션의 가용성과 확장성을 향상시킬 수 있다.

SSL/TLS 암호화: 인그레스를 통해 클러스터 외부에서 들어오는 트래픽을 암호화할 수 있다. <br>
SSL/TLS 인증서를 인그레스에 연결하여 애플리케이션과 클라이언트 간의 통신을 보안할 수 있다.

인그레스는 쿠버네티스 클러스터에 디플로이된 인그레스 컨트롤러를 통해 동작한다. <br>
다양한 인그레스 컨트롤러가 있으며, 가장 널리 사용되는 것은 Nginx Ingress Controller와 Traefik Ingress Controller이다. <br>
인그레스는 YAML 파일을 사용하여 정의되며, 서비스와 함께 사용하여 클러스터 내의 애플리케이션을 외부로 노출시킬 수 있다.



### 질문
#### 디플로이먼트가 지원하는 배포 전략에서 블루/그린이나 카나리는 찾아볼 수 없습니다. 어떻게 블루/그린이나 카나리 배포를 할 수 있을까요?

블루/그린 배포<br>
- 기존에 실행된 pod 개수만큼 신규 pod를 모두 실행한다
- 신규 pod가 정상적으로 실행되면 한꺼번에 트래픽을 옮기는 방식
- 신버전과 구버전이 같이 존재하는 시간 없이 순간적인 교체 가능
- 롤링 업데이트보다 필요한 리소스 양이 많음

초기에는 블루(B) 환경에서 애플리케이션을 실행하고, 
이후에는 새로운 버전인 그린(G) 환경을 구성하고 새로운 버전의 애플리케이션을 배포한다.

로드 밸런서나 인그레스를 사용하여 트래픽을 B 환경에서 G 환경으로 전환한다.
테스트 및 모니터링을 통해 G 환경이 안정적으로 동작하는지 확인한 후, B 환경을 제거한다.

카나리 배포<br>
- 기존 버전을 유지한 채로 일부 버전만 신규 pod로 교체 (한꺼번에 전체 교체 X)
- 구버전과 신버전이 같이 존재한다
- 버그 확인, 사용자 반응 확인할 때 유용

새로운 버전의 애플리케이션을 배포하고, 일부 사용자 또는 일부 트래픽만 새로운 버전으로 전환한다

카나리로 전환된 트래픽에 대해 모니터링을 수행하고, 안정적인 동작을 확인

만약 카나리 배포가 성공적으로 진행된다면, 나머지 트래픽을 새로운 버전으로 전환하고, 문제가 발생하면 카나리 배포된 트래픽을 롤백하거나, 수정된 버전을 재배포하여 안정성을 유지한다.



#### 서비스의 타입은 ClusterIP, NodePort, LoadBalancer, ExternalName 네 가지가 있습니다. 이들은 어떻게 다른가요?
쿠버네티스 환경에서 서비스(Service)는 파드들을 통해 실행되고 있는 애플리케이션을 네트워크에 노출(expose)시키는 가상의 컴포넌트다. 쿠버네티스 내부의 다양한 객체들이 애플리케이션과, 그리고 애플리케이션이 다른 외부의 애플리케이션이나 사용자와 연결될 수 있도록 도와주는 역할을 한다.


1. ClusterIP (기본 형태)<br>
ClusterIP는 파드들이 클러스터 내부의 다른 리소스들과 통신할 수 있도록 해주는 가상의 클러스터 전용 IP다. <br>
이 유형의 서비스는 <ClusterIP>로 들어온 클러스터 내부 트래픽을 해당 파드의 <파드IP>:<targetPort>로 넘겨주도록 동작하므로, 오직 클러스터 내부에서만 접근 가능하게 된다. <br>
쿠버네티스가 지원하는 기본적인 형태의 서비스다.


2. NodePort<br>
NodePort는 외부에서 노드 IP의 특정 포트(<NodeIP>:<NodePort>)로 들어오는 요청을 감지하여, 해당 포트와 연결된 파드로 트래픽을 전달하는 유형의 서비스다. <br>
이때 클러스터 내부로 들어온 트래픽을 특정 파드로 연결하기 위한 ClusterIP 역시 자동으로 생성된다.<br><br>
이 유형의 서비스에서는 spec.ports 아래에 nodePort를 추가로 지정할 수 있다. <br>
nodePort는 외부에서 노드 안의 특정 서비스로 접근할 수 있도록 지정된 노드의 특정 포트를 의미한다.<br> nodePort로 할당 가능한 포트 번호의 범위는 30000에서 32767 사이이며, 미지정시 해당 범위 안에서 임의로 부여된다.



3. LoadBalancer<br>
별도의 외부 로드 밸런서를 제공하는 클라우드(AWS, Azure, GCP 등) 환경을 고려하여, 해당 로드 밸런서를 클러스터의 서비스로 프로비저닝할 수 있는 LoadBalancer 유형도 제공된다.<br>
이 유형은 서비스를 클라우드 제공자 측의 자체 로드 밸런서로 노출시키며, 이에 필요한 NodePort와 ClusterIP 역시 자동 생성된다. <br>
이때 프로비저닝된 로드 밸런서의 정보는 서비스의 status.loadBalancer 필드에 게재된다.


4. ExternalName<br>
서비스에 selector 대신 DNS name을 직접 명시하고자 할 때에 쓰인다. <br>
spec.externalName 항목에 필요한 DNS 주소를 기입하면, 클러스터의 DNS 서비스가 해당 주소에 대한 CNAME 레코드를 반환하게 된다.
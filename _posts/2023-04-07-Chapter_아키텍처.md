---
title:  "네트워크 기초_아키텍처"
excerpt: "DevOps 부트캠프 Section 2 "

categories:
  - Blog
tags:
  - [Blog, DevOps]

toc: true
toc_sticky: true
 
date: 2023-04-07
last_modified_at: 2023-04-07
---
# 아키텍처
컴퓨터 구조(computer architecture)는 컴퓨터 공학에서 개념의 설계이며, 컴퓨터 시스템의 근간이 되는 운영 구조이다. 컴퓨터의 여러 부분에 대해 설계적으로 이식되는 것들과 요구 사항들(특히 속도와 상호 연결)이 무엇인지 기능적으로 설명되어 있는 청사진이다. 주로 중앙 처리 장치 (CPU)가 메모리 주소에 내부적으로 수행하고 접근하는 방법이 집중적으로 설명된다.

하드웨어 부품을 골라서 상호적으로 연결하여 기능, 성능, 비용적인 목표를 충족하는 컴퓨터를 만들어 내는 과학과 기술로 정의될 수도 있다."라고 설명될수있다.

소프트웨어적 의미로는 "소프트웨어 구조(software architecture)는 소프트웨어의 구성요소들 사이에서 유기적 관계를 표현하고 소프트웨어의 설계와 업그레이드를 통제하는 지침과 원칙이다"

<br><br><br>

# 프록시(Proxy)
대리', '대신'이라는 뜻을 가지며, 프로토콜에 있어서는 대리 응답 등에서 사용하는 개념이다.![alt text](/images/proxy.png)<br>
<br>
클라이언트와 서버 사이에 존재하며, 중계기로서 대리로 통신을 수행하는 것을 Proxy라고 하며, 그 중계 기능을 하는 주체를 Proxy Server라고 한다.


## 프록시 서버의 종류
### 포워드 프록시(Forward Proxy)
보통 말하는 프록시가 바로 이 포워드 프록시를 말한다.<br>
Client와 Server 사이에 위치하여 요청을 중계하며, 요청과 응답은 Proxy Server를 거친다.<br>
클라이언트를 감추는 효과가 있다.
![alt text](/images/foward_proxy.png)<br>

장점<br>
캐시 저장(액세스 고속화)
- 프록시 서버에 캐시를 저장할 수 있다.<br>
다시 동일한 페이지를 리퀘스트 했을 때에는 캐시에 남아 있는 정보를 클라이언트에게 준다.<br> 
이것으로 사이트에 접속하는 속도가 빨라진다.


URL 필터링
- 외부의 액세스는 프록시 서버를 경유하므로 사용자 전원의 외부 웹 사이트로의 액세스를 필터링할 수 있다. <br>

### 리버스 프록시(Reverse Proxy)
포워드 프록시와 마찬가지로 요청과 응답이 Proxy Server로 이동하는데, 포워드 프록시와 다르게 Server들이 주로 내부망으로 구성되며 프록시에게만 연결을 허용한다. 즉, 서비스를 위한 보안 채널을 구축한다.<br>
이런 경우 Client가 Server에 직접 접근이 불가능하므로, Reverse Proxy에서 요청을 적극적으로 중계하는 Load Balancing의 역할을 수행하기도 한다.<br>
서버를 감추는 효과가 있다.

장점<br>
부담 분산
- 설정으로 정적 콘텐츠와 동적 콘텐츠의 보는 곳을 나눔으로써 메모리 사용량의 효율화를 할 수 있다. <br>
로드 밸런스와 병용하면 더욱 부담을 분산할 수 있다.

캐시의 저장
- 포워트 프록시와 동일하게 동일한 데이터를 얻을 때에 프록시 서버가 저장했던 내용을 돌려준다.

세큐리티 대책, 바이러스 대책
- 통신시 프록시 서버에 집약되므로 프록시 서버 내에 세큐리티 대책, 바이러스 대책을 구현하여 Web 서버로의 부정 액세스, 사용등을 방지할 수 있다.

## 프록시 서버를 사용하는 이유
개인정보를 보호할 수 있다
- 프록시 서버 없이 클라이언트가 서버에 요청 시 본인의 IP 주소가 노출되는데, 프록시 서버를 사용 시 서버측에서 나의 IP가 아닌 프록시 서버의 IP를 보게 된다.<br>
즉, IP를 숨길 수 있다.


캐시를 사용해서 속도가 향상된다
- 프록시 서버는 웹페이지를 가져올 때 자신의 DB에 최근 데이터를 저장하는데, 이것을 Cache라 한다.<br>
이렇게 될 시, 같은 요청이 들어오면 Cache자원을 반환하여 서비스의 속도를 높이고 대역폭도 줄일 수 있다.


로그를 기록, 관리할 수 있다
- 서버 측에선 클라이언트의 기록대신 프록시 서버의 기록이 있지만, 프록시 서버에겐 클라이언트의 기록이 남아있다.<br>
이 기록들을 보면 어떤 IP에서 어떤 IP로 얼마나 접속해 있는지 확인할 수 있고, 특정 IP가 방문할 수 있는 웹사이트도 제한할 수 있어서 회사에서 많이 사용한다.


접속을 우회할 수 있다
- 특정 사이트에서 IP를 검사해 한국에서의 접속을 차단하는 경우가 있는데, 이런 경우 프록시 서버를 사용해 접속 시 다른나라에서 접속한 것처럼 우회할 수 있다

<br>

>Proxy Chaining<br>
클라이언트의 IP를 숨기기 위해 여러 프록시 서버를 경유하는 기술을 Proxy Chaining 이라고 한다.
예를 들어 Client->Proxy Server1->Proxy Server2... -> Server 처럼 사용하는 것인데, 이렇게 되더라도 프록시 서버를 계속하여 추적하면 클라이언트를 알아낼 수도 있지만 여러 국가에 접속하여 우회하면 알아내기 힘들다.

[reference](https://velog.io/@younghyun/%ED%94%84%EB%A1%9D%EC%8B%9CProxy%EB%9E%80): https://velog.io/@younghyun/%ED%94%84%EB%A1%9D%EC%8B%9CProxy%EB%9E%80

<br><br>

# 로드 밸런싱
네트워크 또는 서버에 가해지는 로드를 분산 해주는 기술<br>
중앙처리장치 혹은 저장장치와 같은 컴퓨터 자원들에게 작업을 나누는 것을 의미

로드밸런싱은 여러 대의 서버를 두고 서비스를 제공하는 분산 처리 시스템에서 필요한 기술이다.

서비스의 제공 초기 단계라면 적은 수의 클라이언트로 인해 서버 한 대로 요청에 응답하는 것이 가능하다. <br>
하지만 사업의 규모가 확장되고, 클라이언트의 수가 늘어나게 되면 기존 서버만으로는 정상적인 서비스가 불가능하게 된다. <br>
증가한 트래픽에 대처할 수 있는 방법은 크게 2가지이다.

1) 수직확장(Scale-up) : 서버 자체의 성능을 확장하는 것. 비유하자면 CPU가 i3인 컴퓨터를 i7으로 업그레이드하는 것과 같다.
2) 수평 확장(Scale-out) : 기존 서버와 동일하거나 낮은 성능의 서버를 두 대 이상 증설하여 운영하는 것을 의미한다. CPU가 i3인 컴퓨터를 여러 대 추가 구입해 운영하 것에 비유할 수 있다.<br>
=> 이 경우, 여러 대의 서버로 트래픽을 균등하게 분산해주는 로드밸런싱이 반드시 필요하다

<br><br>

## 로드밸런서 (Load Balancer)
로드밸런싱 기술을 제공하는 서비스 또는 장치
클라이언트와 네트워크 트래픽이 집중되는 서버들 또는 네트워크 허브 사이에 위치한다.
![alt text](/images/loadbalancer.png)

<br><br>

### L4 Load Balancing
![alt text](/images/l4loadbalancer.png)
전송 계층에서 로드를 분산한다.<br>
IP주소나 포트번호, MAC주소 등에 따라 트래픽을 나누고 분산처리가 가능하다.<br>
CLB(Connection Load Balancer) 혹은 SLB(Session Load Balancer)라고 부르기도 한다.


### L7 Load Balancing 
![alt text](/images/l7loadbalancer.png)
애플리케이션 계층에서 로드를 분산한다.
OSI 7계층의 프로토콜(HTTP, SMTP, FTP 등)을 바탕으로도 분산 처리가 가능하다.



## 로드밸런싱 알고리즘 (Load Balancing Algorithm)
1. 라운드로빈 방식(Round Robin Method)
- 서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식
- 클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고, 서버와의 연결(세션)이 오래 지속되지 않는 경우에 활용하기 적합함.
2. 가중 라운드로빈 방식(Weighted Round Robin Method)
- 각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분하는 방식
- 주로 서버의 트래픽 처리 능력이 상이한 경우 사용되는 부하 분산 방식이다. 예를 들어 A라는 서버가 5라는 가중치를 갖고 B라는 서버가 2라는 가중치를 갖는다면, 로드밸런서는 라운드로빈 방식으로 A 서버에 5개 B 서버에 2개의 요청을 전달함.
3. IP 해시 방식(IP Hash Method)
- 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식
- 사용자의 IP를 해싱해(Hashing, 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수) 로드를 분배하기 때문에 사용자가 항상 동일한 서버로 연결되는 것을 보장함.
4. 최소 연결 방식(Least Connection Method)
- 요청이 들어온 시점에 가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분하는 방식
- 자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합함.
5. 최소 리스폰타임(Least Response Time Method)
- 서버의 현재 연결 상태와 응답시간(Response Time, 서버에 요청을 보내고 최초 응답을 받을 때까지 소요되는 시간)을 모두 고려하여 트래픽을 배분하는 방식
- 가장 적은 연결 상태와 가장 짧은 응답시간을 보이는 서버에 우선적으로 로드를 배분함.

[reference](https://velog.io/@yanghl98/OS%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-Load-Balancing-%EC%A0%95%EC%9D%98-%EC%A2%85%EB%A5%98-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98): https://velog.io/@yanghl98/OS%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-Load-Balancing-%EC%A0%95%EC%9D%98-%EC%A2%85%EB%A5%98-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98

<br><br><br>

# 캐시(cache)
컴퓨터 공학 전반에서 이야기되는 캐시는 자주 사용되는 데이터를 임시로 복사해두는 임의의 장소를 의미한다. <br>
그리고 데이터를 캐시에 저장하는 행위를 캐싱이라고 한다. <br>
일반적으로 캐싱은 캐시에 저장된 데이터에 접근하는 시간에 비해 원본 데이터에 접근하는 시간이 오래 걸리는 경우 사용한다.


## HTTP 캐시
앞서 설명했듯이 캐시는 자주 사용하는 데이터에 더 빠르게 접근하기 위해 사용한다. 데이터 접근을 위해 네트워크를 사용해야하는 웹 환경에서도 캐시는 유용하게 사용할 수 있다. <br>
HTTP 캐싱을 활용하면 웹 사이트의 로딩 시간을 개선할 수 있다.

특히 이미지 혹은 JS, CSS와 같은 파일들은 자주 변하지 않는다. <br>
캐시를 사용하지 않으면 자주 변하지 않는 데이터라도 요청마다 새롭게 다운로드 해야한다. <br>
이는 불필요한 네트워크 비용 발생을 야기하고, 서버에 추가적인 부담을 준다. <br>
이는 곧 느린 웹페이지 로딩 속도로 직결되고, 좋지 않은 사용자 경험을 유발할 것 이다.


### HTTP 캐시 종류
Private Cache
- 웹 브라우저에 저장되는 캐시이며, 다른 사람이 접근할 수 없다. <br>
단, 서버 응답에 Authorization 헤더가 포함되어 있다면 Private Cache에 저장되지 않는다.

Shared Cache
- Shared Cache 는 웹 브라우저와 서버 사이에서 동작하는 캐시를 의미하며, 다시 Proxy Cache와 Managed Cache 2가지로 나뉜다.

Proxy Cache(public Cache?)
- (포워드) 프록시에서 동작하는 캐시이다.

Managed Cache
- AWS Cloudfront 혹은 Cloudflare 와 같은 CDN 서비스 그리고 리버스 프록시에서 동작하는 캐시이다. <br>
이런 서비스들의 관리자 패널에서 직접 캐시에 대한 설정을 관리하거나 리버스 프록시 설정으로 관리할 수 있으므로 Managed Cache라고 불린다.


### Cache-Control
Cache-Control 은 HTTP 에서 캐시 메커니즘을 지정하기 위해 사용되는 헤더이다.<br> 많은 디렉티브(directive)가 있지만, max-age 라는 디렉티브를 사용하면 캐시의 최대 수명을 설정할 수 있다. <br>
이때, max-age의 단위는 초 이다.
```
HTTP/1.1 200 OK
Content-Type: text/html
Cache-Control: max-age=3600
Content-Length: 157

<!DOCTYPE HTML>
<html lang="ko">
<head>
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"/>
</head>
<body>
Hello, World!
</body>
</html>
```
웹 브라우저가 특정 리소스에 최초로 요청했을 경우 서버는 아래와 같이 Cache-Control 헤더가 포함된 응답을 보낸다. <br>
위 응답을 받은 웹 브라우저는 응답 결과를 3600초 즉, 1시간 동안 캐시에 저장한다.

이후 웹 브라우저가 같은 리소스에 요청을 보내면, 실제 웹 서버에 요청을 보내는 것이 아니라 캐시에 저장한 사본 데이터를 사용자에게 제공한다.

max-age 디렉티브에 명시한 캐시 유효 시간이 지난 이후 동일한 리소스를 요청하면, 그때는 실제로 웹 서버에 리소스를 요청한다. <br>
이때, 캐시된 데이터가 지정된 캐시 시간을 지나지 않아 유효한 경우 신선하다(fresh)라고 표현하며, 캐시 시간이 초과된 경우는 신선하지 않다(stale)라고 표현한다.


### 캐시 유효성 검증 및 조건부 요청
캐시의 유효 기간이 지난 다음 다시 서버에 리소스를 요청하면 둘 중 하나일 것 이다. <br>
이전과 다르지 않은 데이터를 그대로 받거나, 새롭게 갱신된 데이터를 받거나. <br>
이때, 전자의 경우에는 의미 없는 트래픽을 낭비한 것이 된다.

이런 트래픽 낭비를 줄이기 위해, 실제 원본 데이터가 수정 되었을 때만 리소스를 내려 받는것이 바람직하다. <br>
이런 과정을 캐시 유효성 검증(validation) 및 조건부 요청(conditional request)이라고 한다.

이 방식은 크게 2가지로 나뉜다. <br>
첫번째로는 리소스의 마지막 갱신 시각으로 검증하는 Last-Modified 와 If-Modified-Since 를 사용하는 방법, 두번째로는 리소스의 식별자를 기준으로 검증하는 ETag 와 If-None-Match 를 사용하는 방법이다.


#### Last-Modified / If-Modified-Since
최초 요청 시 응답
```
HTTP/1.1 200 OK
Content-Type: text/html
Cache-Control: max-age=3600
Last-Modified: Sat, 03 Sep 2022 00:00:00 GMT
Content-Length: 157

<!DOCTYPE HTML>
<html>
...
```
아까와 동일한 응답이다. <br>
단, 여기에 Last-Modified 라는 헤더가 추가되었다. 이 헤더에는 요청한 리소스가 마지막으로 수정된 일자를 나타낸다.<br> 브라우저는 이 Last-Modified 를 저장해둔다.

두번째 요청
```
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-Modified-Since: Sat, 03 Sep 2022 00:00:00 GMT
```
이후 캐시 기간이 초과되어 두번째 요청 시 브라우저는 저장해둔 Last-Modified 값을 If-Modified-Since 라는 요청 헤더에 넣어 서버로 요청을 보낸다.

리소스가 변경되지 않았을 경우
```
HTTP/1.1 304 Not Modified
Content-Type: text/html
Cache-Control: max-age=3600
Last-Modified: Sat, 03 Sep 2022 00:00:00 GMT
```
만약 위와 같이 조건부 요청을 보냈는데, 원본 리소스에 아무런 변경이 없었다면, 서버는 위와 같이 304 Not Modified 라는 상태 코드로 응답한다. <br>
또한 이 응답에는 Response Body가 없기 때문에 트래픽을 아낄 수 있다.


#### ETag / If-None-Match
앞서 소개한 방법은 밀리 세컨드 단위로 시각을 설정할 수 없다는 한계점이 존재한다.<br> ETag란 특정 버전의 리소스를 식별하기 위해 사용하는 식별자이다. <br>
이를 통해 Last-Modified / If-Modified-Since 의 단점을 극복할 수 있다.

최초 요청 시 응답
```
HTTP/1.1 200 OK
Content-Type: text/html
Cache-Control: max-age=3600
ETag: "abcdefg"
Content-Length: 157

<!DOCTYPE HTML>
<html>
...
```
리소스에 대한 최초 요청 시 ETag 라는 응답 헤더가 돌아온다. <br>
요청한 리소스의 현재 버전에 대한 식별자이다. <br>
브라우저는 이 ETag 값을 저장한다.

두번째 요청
```
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-None-Match: "abcdefg"
```
이후 캐시 기간이 초과되어 리소스에 대해 재요청시 If-None-Match 라는 헤더에 저장해둔 ETag 값을 넣어서 보낸다.

리소스가 변경되지 않았을 경우
```
HTTP/1.1 304 Not Modified
Content-Type: text/html
Cache-Control: max-age=3600
Last-Modified: "abcdefg"
```
마찬가지로 리소스가 변경되지 않은 경우 서버는 Response Body를 제외하고, 304 Not Modified 로 응답한다.



### no-cache, no-store
유저에게 항상 최신 버전의 리소스만을 제공하고 싶을 경우가 있을 것이다. <br>
이때, 항상 최신 버전의 리소스를 캐시하거나, 혹은 아예 캐시 자체를 하지 않는 방법이 있다.

이런 옵션을 위해서 웹 브라우저가 요청을 보낼 때 Cache-Control 헤더에 no-cache 혹은 no-store 디렉티브를 포함할 수 있다.

#### no-cache
이름 때문에 헷갈리지 말자. <br>
no-cache 는 캐시를 아예 생성하지 않는 옵션이 아니다. <br>
리소스에 대한 캐시를 생성하지만, 리소스를 요청할 때 원 서버에 항상 캐시 유효성 검증을 하는 옵션이다.

#### no-store
no-store 는 리소스에 대한 캐시를 생성하지 말라는 가장 강력한 Cache-Control 디렉티브이다. <br>
저장하면 안되는 민감한 정보일 때 사용한다.

#### must-revaildate
캐시 만료 후 최초 조회 시 원 서버에 검증해야 한다.<br>
원 서버 접근 실패 시 반드시 오류가 발생해야 한다. - 504(Gateway Timeout)<br>
must-revaildate는 캐시 유효 시간이라면 캐시를 사용한다.

#### no-cache 와 must-revaildate의 차이점
no-cache는 캐시 서버 요청을 하면 프록시 캐시 서버에 도착하면 원 서버에 요청한다.

만약 프록시 캐시 서버와 원 서버 사이에서 네트워크 단절이 일어나 접근이 불가능하다면, no-cache에서 오류가 아닌 오래된 데이터라도 보여주자라는 개념으로 200OK을 응답으로 내보낸다.

must-revaildate는 만약 접근이 불가능 하다면 504(Gateway Timeout)라는 오류를 내보낸다. <br>
중요한 정보를 사용할 경우 예전 데이터를 보여준다면 큰 문제가 발생하기 때문에 이러한 경우는 must-revaildate를 적용한다.

### private vs public
앞서 Private Cache와 Shared Cache에 대해서 이야기했다. <br>
Cache-Control 헤더의 private 또는 public 디렉티브를 사용하여 캐시 허용 범위를 지정할 수 있다.

public 디렉티브를 사용하면 Shared Cache 에서도 캐싱을 허용하고, private 디렉티브를 사용하면 사용자 브라우저에게만 캐싱을 허용한다.
```
Cache-Control: max-age=3600, private;
```
기존 디렉티브와 함께 사용하려면 위와 같이 , 로 구분한다.

[reference](https://hudi.blog/http-cache/) : https://hudi.blog/http-cache/

<br><br>


## 프록시 캐시
한국에 있는 클라이언트(웹 브라우저)가 외국의 원 서버에 있는 특정 데이터가 필요한 상황이라고 가정해보자.<br>
정보를 가져오기 위해서 많은 시간이 소요될 수 있다.<br>
이 때 외국이 원 서버와 한국 클라이언트의 중간에 위치한 한국의 캐시 서버가 있다면 여기서 데이터를 가져올 수 있기 때문에 시간을 줄일 수 있다. <br>
또한 여러 사람이 찾은 자료일수록 캐시에 이미 등록되어 있으면 빠른 속도로 데이터를 가져올 수 있다.<br>
(국내에 프록시 캐시 서버가 있기 때문에 외국의 원 서버에서 데이터를 가져오는 것보다 빠르다.)

이러한 클라이언트에서 사용하고 저장하는 캐시를 private캐시라 하며 프록시 캐시를 public이라고 한다.

[reference](https://velog.io/@gkrba1234/%ED%94%84%EB%A1%9D%EC%8B%9C-%EC%BA%90%EC%8B%9CProxy-Cache%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90): https://velog.io/@gkrba1234/%ED%94%84%EB%A1%9D%EC%8B%9C-%EC%BA%90%EC%8B%9CProxy-Cache%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90

<br><br>

## CDN
CDN은 Content Delivery Network의 약자로서 지리적인 제약 없이 전 세계 사용자에게 빠르고 안전하게 컨텐츠 전송을 할 수 있는 기술을 말한다. <br>
이를 통해서 컨텐츠의 병목현상을 피할 수 있다.

CDN(Content Delivery Network)은 물리적으로 떨어져 있는 사용자에게 컨텐츠를 더 빠르게 제공하기 위해 고안된 기술이다. <br>
만약 우리나라에 있는 사람이 미국에 있는 서버로부터 이미지나 파일 등을 다운받으려고 한다면 시간이 오래 걸릴 것이다.<br>
따라서 서버를 분산시켜 캐싱해두고 사용자의 컨텐츠 요청이 들어오면 사용자와 가장 가까운 위치에 존재하는 서버로 매핑시켜 요청된 콘텐츠의 캐싱된 내용을 내어주는 방식으로 빠르게 데이터를 전송할 수 있게 된다.<br>
만약 서버가 파일을 찾는데 실패하는 경우 CDN 플랫폼의 다른 서버에서 컨텐츠를 찾은다음 응답을 전송한다.

CDN의 동작을 살펴보면 다음과 같은 규칙으로 수행된다.

1. 최초 요청은 서버로부터 컨텐츠를 가져와 고객에게 전송하며 동시에 CDN 캐싱장비에 저장한다.
2. 최초 요청 이후로의 요청은 CDN 에서 지정하는 해당 컨텐츠 만료 시점까지 캐싱된 컨텐츠를 전송한다.
3. 자주 사용하는 페이지에 한해서 캐싱되며, 해당 컨텐츠 호출이 없을 경우 주기적으로 삭제된다.
4. 서버가 파일을 찾는데 실패하는 경우 CDN 플랫폼의 다른 서버에서 컨텐츠를 찾은다음 엔드유저에게 응답을 전송한다.
5. 컨텐츠를 사용할 수 없거나 오래된 경우 CDN은 향후 요청에 대해 응답할 수 있도록 새로운 컨텐츠를 저장한다.

### CDN 캐싱 방식
Static Caching
- Origin Server 에 있는 Content를 운영자가 미리 Cache Server에 복사 해두어 사용자가 Cache Server에 Content 요청 시 무조건 Cache Server에 있다
- 대부분의 국내 CDN에서 이 방식을 사용 (게임 클라이언트 다운로드 등)
Dynamic Caching
- Origin Server에 있는 Content를 운영자가 미리 Cache Server에 복사하지 않음
- 사용자가 Content를 요청 시 해당 Content가 없는 경우 Origin Server로부터 다운로드 받아 전달한다. 있는 경우에는 캐싱된 Content전달
- 각각의 Content는 일정 시간 이후 Cache Server에서 삭제 될 수도 있다.

### CDN 컨텐츠
컨텐츠는 동적컨텐츠와 정적 컨텐츠로 나눌 수 있다.

- 정적 컨텐츠 : HTML, 이미지파일, 동영상 등의 바이너리 데이터 고정된 컨텐츠
- 동적 컨텐츠 : API조회 결과 등(게시판의 최신 글) 유동적인 컨텐츠 

### 사용 이유
CDN 없이도 동작하지만 많은 서비스들이 CDN을 사용하는데 이유가 있다.
그전에 CDN은 여러개의 지역에 배치시켜 사용한다. 

- 물리적거리 <br> 
CDN 도입 시 빠른 콘텐츠 제공 속도는 매우 중요하다. <br>
Static Contents에 대해 Web Server가 아닌 CDN을 통해 사용자의 위치와 가까운 곳에 있는 CDN Cache Server에서 데이터를 리턴한다.<br> 
예를 들면 서울에 있는 사용자는 서울에 있는 Edge 서버에서, 부산 사용자는 부산 Edge서버에서 이용하여 사용자가 분산된 서버를 통해 이용하는 효과가 있다. <br>
같은말로 원래는 오리지널서버에 요청을 해서 데이터를 받게되면 만약 오리지널서버는 한국에 있고 요청한 사용자는 미국에 위치한다면 아마 응답을 받는데 시간이 오래걸릴 것이다. <br>
그래서 CDN을 통해서 미국에있는 CDN에 요청이 가도록 하여 사이트를 보다 빠르게 이용 가능하도록합니다. <br>
비유를 하면 본사가 아니라 체인점을 여러개 둬서 체인점으로 요청을 보내서 체인점에 데이터를 주면 본사에 가지 않아도 가까운 체인점을 방문하면 빠르게 받을 수 있는 것과 같다. <br>
추가적으로 여기서 체인점과 같이 세계 각지의 서버를 Edge라고 부릅니다.

 

- 부하분산<br>
사용자의 요청이 증가하고 트래픽이 갑자기 증가하거나 Contents양이 증가하는 경우 웹서버의 부하가 집중되어 서비스 안정성이 저해되고 장애가 발생할 가능성이 있다. <br>
이떄 CDN도입을 통해 WebServer의 부하를 줄일 수 있다.<br>
물리적 거리 뿐만 아니라 특정지역에 너무 많은 요청이 오면 엣지들의 헬스체크를 해서 다른곳으로 요청을 보낼수도있다. <br>
이런 방식으로 부하분산이 가능하다.


- CDN업체에 나가는비용도있지만 본서버 돌리는 비용도 줄어든다.<br>
서버로직접 요청되지 않기 때문에 대역폭 비용이 크게 절감된다.<br>
즉 본사로 직접 요청이 오지않기떄문에 오리지날서버로 가는길을 넓게 깔 필요가 없다.<br>
이런측면에서 서버호스팅 비용이 절감된다.

 

🍧대역폭이란?
주어진 시간안에 데이터 얼마나 많이 실려지고 보내질 수 있는지이다.<br>
컴퓨터 네트워크에서 데이터 빨리보내는지를 보려면 전송속도랑 대역폭이 얼마나 되는지 보는 것이 일반적이다.<br>
예시로 도로가 있는데 전송속도는 이 도로의 제한속도이고 대역폭은 차선이다.<br>
대역폭이 넓다면 같은속도에서도 많은 데이터가 실려갈수있는것이다.<br>
전송속도는 물리적거리를 얼마나 빠르게 이동하는가 대역폭은 동시에 얼마나 많은 데이터가 오고 갈수있는가를 나타낸다.

 
- 가용성과 안전성도 증가된다.<br>
본서버가받는 부담이덜어지니까 과부하로인한 오류도줄어들고 하나의 엣지가 이상이 생겨도 다른엣지로 연결되기떄문에 보다 안정적인 서비스를 제공할 수 있다.
헬스체크 : 잘돌고있는지 꾸준히 관리를해준다.

 

- 보안
보안적인 부분에서도 이점을 준다. <br>
Ddos 공격처럼 지정되는 시간에 좀비떼들마냥 몰려가서 요청을 많이하면 서버가 다운되지만
분산처리를 하기때문에 조금 더 버틸수있다.<br> 
또한 CDN에 정상적인 요청과 비정상적인 요청을 구분해내어 특정 시점의 요청수를 제한하거나 집중된요청을 분산시키는 등 Ddos에대해 무력화 시킬 방법을 가지고 있다.

[reference](https://velog.io/@youngblue/CDN%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80): https://velog.io/@youngblue/CDN%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80
[reference](https://cwangg897.tistory.com/93) : https://cwangg897.tistory.com/93